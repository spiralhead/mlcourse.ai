{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "403f8973-1fb5-422c-bd82-fb5d7041d8b2",
    "_uuid": "091313c11c12aaeef8bc25b39a205f79bb2588a6",
    "collapsed": true
   },
   "source": [
    "<img src=\"https://habrastorage.org/webt/ia/m9/zk/iam9zkyzqebnf_okxipihkgjwnw.jpeg\" />\n",
    "    \n",
    "**<center>[mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course** </center><br>\n",
    "\n",
    "Author: [Yury Kashnitskiy](https://yorko.github.io). Translated and edited by [Serge Oreshkov](https://www.linkedin.com/in/sergeoreshkov/), and [Yuanyuan Pao](https://www.linkedin.com/in/yuanyuanpao/). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Topic 8. Vowpal Wabbit: Learning with Gigabytes of Data</center><a class=\"tocSkip\">\n",
    "\n",
    "This week, we’ll cover two reasons for Vowpal Wabbit’s exceptional training speed, namely, online learning and hashing trick, in both theory and practice. We will try it out with news, movie reviews, and StackOverflow questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a783ea16-a0be-4a81-9d91-72c9ada412d0",
    "_uuid": "aba8923437f1bb67ff9615f218dbe3cb19145f4e"
   },
   "source": [
    "# Outline\n",
    "1. [Stochastic gradient descent and online learning](#1.-Stochastic-gradient-descent-and-online-learning)\n",
    "    - 1.1. [SGD](#1.1.-Stochastic-gradient-descent)\n",
    "    - 1.2. [Online approach to learning](#1.2.-Online-approach-to-learning)\n",
    "2. [Categorical feature processing](#2.-Categorical-feature-processing)\n",
    "    - 2.1. [Label Encoding](#2.1.-Label-Encoding)\n",
    "    - 2.2. [One-Hot Encoding](#2.2.-One-Hot-Encoding)\n",
    "    - 2.3. [Hashing trick](#2.3.-Hashing-trick)\n",
    "3. [Vowpal Wabbit](#3.-Vowpal-Wabbit)\n",
    "    - 3.1. [News. Binary classification](#3.1.-News.-Binary-classification)\n",
    "    - 3.2. [News. Multiclass classification](#3.2.-News.-Multiclass-classification)\n",
    "    - 3.3. [IMDB movie reviews](#3.3.-IMDB-movie-reviews)\n",
    "    - 3.4. [Classifying gigabytes of StackOverflow questions](#3.4.-Classifying-gigabytes-of-StackOverflow-questions)\n",
    "4. [Demo assignment](#4.-Demo-assignment)\n",
    "5. [Useful resources](#5.-Useful-resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "64efb6ef-3591-4036-8461-b7b467f404b7",
    "_uuid": "bd1f11458028d021571d4a77e3de846bf0dee992"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.datasets import fetch_20newsgroups, load_files\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, log_loss, roc_auc_score,\n",
    "                             roc_curve)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ddb2276a-dd17-4229-8a0b-1860056dc08a",
    "_uuid": "8c3581ddac23e8621f7688aec41bbce23e91bc6c"
   },
   "source": [
    "## 1. Stochastic gradient descent and online learning\n",
    "###  1.1. Stochastic gradient descent\n",
    "\n",
    "Despite the fact that gradient descent is one of the first things learned in machine learning and optimization courses, it is one of its modifications, Stochastic Gradient Descent (SGD), that is hard to top.\n",
    "\n",
    "Recall that the idea of gradient descent is to minimize some function by making small steps in the direction of the fastest decrease. This method was named due to the following fact from calculus: vector $\\nabla f = (\\frac{\\partial f}{\\partial x_1}, \\ldots \\frac{\\partial f}{\\partial x_n})^\\text{T}$ of partial derivatives of the function $f(x) = f(x_1, \\ldots x_n)$ points to the direction of the fastest function growth. It means that, by moving in the opposite direction (antigradient), it is possible to decrease the function value with the fastest rate.\n",
    "\n",
    "<img src='https://habrastorage.org/files/4f2/75d/a46/4f275da467a44fc4a8d1a11007776ed2.jpg' width=50%>\n",
    "\n",
    "Here is a snowboarder (me) in Sheregesh, Russia's most popular winter resort. (I highly recommended it if you like skiing or snowboarding). In addition to advertising the beautiful landscapes, this picture depicts the idea of gradient descent. If you want to ride as fast as possible, you need to choose the path of steepest descent. Calculating antigradients can be seen as evaluating the slope at various spots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eda14ceb-ab19-4c75-a1ad-bbbbf3acb83d",
    "_uuid": "7c41b31a7549e4dbcd0c31824d425d18ec6b9fbb"
   },
   "source": [
    "**Example**\n",
    "\n",
    "The paired regression problem can be solved with gradient descent. Let us predict one variable using another: height with weight. Assume that these variables are linearly dependent. We will use the [SOCR](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data) dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Jupyter-book, we copy data from GitHub, locally, to save Internet traffic,\n",
    "# you can specify the data/ folder from the root of your cloned \n",
    "# https://github.com/Yorko/mlcourse.ai repo, to save Internet traffic\n",
    "DATA_PATH = \"https://raw.githubusercontent.com/Yorko/mlcourse.ai/master/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "84022022-7ce2-4fac-90ae-3cefc5a12961",
    "_uuid": "0873cf8a28158f2ebdd5b3b42d3026efcd8e6b58"
   },
   "outputs": [],
   "source": [
    "PATH_TO_WRITE_DATA = \"../../tmp/\"\n",
    "data_demo = pd.read_csv(os.path.join(DATA_PATH, \"weights_heights.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "094aa0fc-8af4-4a13-88a7-4eedf53fd712",
    "_uuid": "a60148fd610f423b517a38dad8768f0f6c76d192"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data_demo[\"Weight\"], data_demo[\"Height\"])\n",
    "plt.xlabel(\"Weight in lb\")\n",
    "plt.ylabel(\"Height in inches\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1140d0cf-9aef-4d4b-8d74-86795ef71737",
    "_uuid": "ad436575e565a80eecc4a9fde161065ff1f22f9f"
   },
   "source": [
    "Here we have a vector $x$ of dimension $\\ell$ (weight of every person i.e. training sample) and $y$, a vector containing the height of every person in the dataset. \n",
    "\n",
    "The task is the following: find weights $w_0$ and $w_1$ such that predicting height as $y_i = w_0 + w_1 x_i$ (where $y_i$ is $i$-th height value, $x_i$ is $i$-th weight value) minimizes the squared error (as well as mean squared error since $\\frac{1}{\\ell}$ doesn't make any difference ):\n",
    "$$SE(w_0, w_1) = \\frac{1}{2}\\sum_{i=1}^\\ell(y_i - (w_0 + w_1x_{i}))^2 \\rightarrow min_{w_0,w_1}$$\n",
    "\n",
    "We will use gradient descent, utilizing the partial derivatives of $SE(w_0, w_1)$ over weights $w_0$ and $w_1$.\n",
    "An iterative training procedure is then defined by simple update formulas (we change model weights in small steps, proportional to a small constant $\\eta$, towards the antigradient of the function $SE(w_0, w_1)$):\n",
    "\n",
    "$$\\begin{array}{rcl} w_0^{(t+1)} = w_0^{(t)} -\\eta \\frac{\\partial SE}{\\partial w_0} |_{t} \\\\  w_1^{(t+1)} = w_1^{(t)} -\\eta \\frac{\\partial SE}{\\partial w_1} |_{t} \\end{array}$$\n",
    "\n",
    "Computing the partial derivatives, we get the following: \n",
    "\n",
    "$$\\begin{array}{rcl} w_0^{(t+1)} = w_0^{(t)} + \\eta \\sum_{i=1}^{\\ell}(y_i - w_0^{(t)} - w_1^{(t)}x_i) \\\\  w_1^{(t+1)} = w_1^{(t)} + \\eta \\sum_{i=1}^{\\ell}(y_i - w_0^{(t)} - w_1^{(t)}x_i)x_i \\end{array}$$\n",
    "\n",
    "This math works quite well as long as the amount of data is not large (we will not discuss issues with local minima, saddle points, choosing the learning rate, moments and other stuff –- these topics are covered very thoroughly in [the Numeric Computation chapter](http://www.deeplearningbook.org/contents/numerical.html) in \"Deep Learning\"). \n",
    "There is an issue with batch gradient descent -- the gradient evaluation requires the summation of a number of values for every object from the training set. In other words, the algorithm requires a lot of iterations, and every iteration recomputes weights with formula which contains a sum $\\sum_{i=1}^\\ell$ over the whole training set. What happens when we have billions of training samples?\n",
    "\n",
    "<img src=\"https://habrastorage.org/webt/ow/ng/cs/owngcs-lzoguklv1pn9vz_r4ssm.jpeg\" />\n",
    "\n",
    "Hence the motivation for stochastic gradient descent! Simply put, we throw away the summation sign and update the weights only over single training samples (or a small number of them). In our case, we have the following:\n",
    "\n",
    "$$\\begin{array}{rcl} w_0^{(t+1)} = w_0^{(t)} + \\eta (y_i - w_0^{(t)} - w_1^{(t)}x_i) \\\\  w_1^{(t+1)} = w_1^{(t)} + \\eta (y_i - w_0^{(t)} - w_1^{(t)}x_i)x_i \\end{array}$$\n",
    "\n",
    "With this approach, there is no guarantee that we will move in best possible direction at every iteration. Therefore, we may need many more iterations, but we get much faster weight updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dc9f67f3-4110-40b6-b7bd-a2736233d10f",
    "_uuid": "7d61f90cd77f5fc64646a22cdcaaa3e9ee012ebc"
   },
   "source": [
    "Andrew Ng has a good illustration of this in his [machine learning course](https://www.coursera.org/learn/machine-learning). Let's take a look.\n",
    "\n",
    "<img src='https://habrastorage.org/files/f8d/90c/f83/f8d90cf83b044255bb07df3373f25fc7.png'>\n",
    "\n",
    "These are the contour plots for some function, and we want to find the global minimum of this function. The red curve shows weight changes (in this picture, $\\theta_0$ and $\\theta_1$ correspond to our $w_0$ and $w_1$). According to the properties of a gradient, the direction of change at every point is orthogonal to contour plots. With stochastic gradient descent, weights are changing in a less predictable manner, and it even may seem that some steps are wrong by leading away from minima; however, both procedures converge to the same solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3583f288-f80e-4853-82d6-d3bdc5da50f5",
    "_uuid": "fbf630784df546a50ad03c698537e2b0980057a0"
   },
   "source": [
    "### 1.2. Online approach to learning\n",
    "Stochastic gradient descent gives us practical guidance for training both classifiers and regressors with large amounts of data up to hundreds of GBs (depending on computational resources).\n",
    "\n",
    "Considering the case of paired regression, we can store the training data set $(X,y)$ in HDD without loading it into RAM (where it simply won't fit), read objects one by one, and update the weights of our model:\n",
    "\n",
    "$$\\begin{array}{rcl} w_0^{(t+1)} = w_0^{(t)} + \\eta (y_i - w_0^{(t)} - w_1^{(t)}x_i) \\\\  w_1^{(t+1)} = w_1^{(t)} + \\eta (y_i - w_0^{(t)} - w_1^{(t)}x_i)x_i \\end{array}$$\n",
    "\n",
    "After working through the whole training dataset, our loss function (for example, quadratic squared root error in regression or logistic loss in classification) will decrease, but it usually takes dozens of passes over the training set to make the loss small enough. \n",
    "\n",
    "This approach to learning is called **online learning**, and this name emerged even before machine learning MOOC-s turned mainstream.\n",
    "\n",
    "We did not discuss many specifics about SGD here. If you want dive into theory, I highly recommend [\"Convex Optimization\" by Stephen Boyd](https://www.amazon.com/Convex-Optimization-Stephen-Boyd/dp/0521833787). Now, we will introduce the Vowpal Wabbit library, which is good for training simple models with huge data sets thanks to stochastic optimization and another trick, feature hashing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "abaadfeb-a49c-4fc9-8cc4-c7739e4f9edc",
    "_uuid": "23782a78c5bac799ed50cc994f3768163fc70a7c"
   },
   "source": [
    "In scikit-learn, classifiers and regressors trained with SGD are named  `SGDClassifier` and `SGDRegressor` in `sklearn.linear_model`. These are nice implementations of SGD, but we'll focus on VW since it is more performant than sklearn's SGD models in many aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9bb0708a-2e81-4040-816b-9dee68595d3f",
    "_uuid": "56b085b90c338a0e436544c2c5345d7a2716f612"
   },
   "source": [
    "## 2. Categorical feature processing\n",
    "\n",
    "### 2.1. Label Encoding\n",
    "Many classification and regression algorithms operate in Euclidean or metric space, implying that data is represented with vectors of real numbers. However, in real data, we often have categorical features with discrete values such as yes/no or January/February/.../December. We will see how to process this kind of data, particularly with linear models, and how to deal with many categorical features even when they have many unique values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "44ebb1ca-8d55-47a1-bfa1-0c1bee8ce99f",
    "_uuid": "29058442a542088bb018bcf8158fcbbf4e79cef8"
   },
   "source": [
    "Let's explore the [UCI bank marketing dataset](https://archive.ics.uci.edu/ml/datasets/bank+marketing) where most of  features are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "be6b51fd-ad36-4265-9086-fde116c6d5e4",
    "_uuid": "c8f015ed0ce62cdfc232529b9db5e17f1ebf55f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>mon</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.961</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>131</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.864</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>tue</td>\n",
       "      <td>404</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.469</td>\n",
       "      <td>-33.6</td>\n",
       "      <td>1.044</td>\n",
       "      <td>5076.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nov</td>\n",
       "      <td>mon</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.191</td>\n",
       "      <td>5195.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital          education  default housing loan  \\\n",
       "0   26      student   single        high.school       no      no   no   \n",
       "1   46       admin.  married  university.degree       no     yes   no   \n",
       "2   49  blue-collar  married           basic.4y  unknown     yes  yes   \n",
       "3   31   technician  married  university.degree       no      no   no   \n",
       "4   42    housemaid  married  university.degree       no     yes   no   \n",
       "\n",
       "     contact month day_of_week  duration  campaign  pdays  previous  \\\n",
       "0  telephone   jun         mon       901         1    999         0   \n",
       "1   cellular   aug         tue       208         2    999         0   \n",
       "2  telephone   jun         tue       131         5    999         0   \n",
       "3   cellular   jul         tue       404         1    999         0   \n",
       "4  telephone   nov         mon        85         1    999         0   \n",
       "\n",
       "      poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0  nonexistent           1.4          94.465          -41.8      4.961   \n",
       "1  nonexistent           1.4          93.444          -36.1      4.963   \n",
       "2  nonexistent           1.4          94.465          -41.8      4.864   \n",
       "3  nonexistent          -2.9          92.469          -33.6      1.044   \n",
       "4  nonexistent          -0.1          93.200          -42.0      4.191   \n",
       "\n",
       "   nr.employed  \n",
       "0       5228.1  \n",
       "1       5228.1  \n",
       "2       5228.1  \n",
       "3       5076.2  \n",
       "4       5195.8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"bank_train.csv\"))\n",
    "labels = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, \"bank_train_target.csv\"), header=None\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d81909b1-6b0f-47f5-9d10-f983fe1edcc7",
    "_uuid": "d900d6aa25e49a150388a9618b8f36bb76ac8667"
   },
   "source": [
    "We can see that most of features are not represented by numbers. This poses a problem because we cannot use most machine learning methods (at least those implemented in scikit-learn) out-of-the-box.\n",
    "\n",
    "Let's dive into the \"education\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "d5cb0f31-1e52-49a0-9bdb-ae3207541710",
    "_uuid": "136b05d444ff42d4e8521e51066bf9cd22c023fa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"education\"].value_counts().plot.barh();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca94e540-92a0-41bb-a67b-906275c778e9",
    "_uuid": "284a387b80dba61981db40dabd3fc2f895616011"
   },
   "source": [
    "The most straightforward solution is to map each value of this feature into a unique number. For example, we can map  `university.degree` to 0, `basic.9y` to 1, and so on. You can use `sklearn.preprocessing.LabelEncoder` to perform this mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "fb569cfb-711b-428d-9a29-5393dff4b348",
    "_uuid": "05c9087139ca3fcdf3b715b9b30f566bdaf0ad1c"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e75f24ed-b8ed-41dd-96c2-dcd1f42d7014",
    "_uuid": "276ccbe10a9744f1cca107fb5b7542a314b961fa"
   },
   "source": [
    "The `fit` method of this class finds all unique values and builds the actual mapping between categories and numbers, and the `transform` method  converts the categories into numbers. After `fit` is executed, `label_encoder` will have the `classes_` attribute with all unique values of the feature. Let us count them to make sure the transformation was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c692cf31-3233-4b92-8bb9-de7d7be15315",
    "_uuid": "efe26525483e1c3ba137e8f1c55f92c76ab4c799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'basic.4y', 1: 'basic.6y', 2: 'basic.9y', 3: 'high.school', 4: 'illiterate', 5: 'professional.course', 6: 'university.degree', 7: 'unknown'}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOUElEQVR4nO3df6zddX3H8edrV1CLWlTQdC3xYkJIiN3A3TAZi9lAHajBf/YHJG66uPSfbZFtiSkxWeJ/27IYt2wxa/wxMxWjCJuh/iIqMS4beIrFFkunaJUWtbjFC9pkan3vj/O99tLetqf1fNt36PORnJzv+Z5vP/cFvffV7/2c7/mcVBWSpL5+5WwHkCSdmEUtSc1Z1JLUnEUtSc1Z1JLU3DPGGPSiiy6qxcXFMYaWpKelHTt2/KCqLl7ruVGKenFxkclkMsbQkvS0lOTbx3vOqQ9Jas6ilqTmLGpJas6ilqTmLGpJas6ilqTmLGpJas6ilqTmLGpJam7mok6ykOQrSe4eM5Ak6alO5Yz6rcCesYJIktY2U1En2QS8DnjPuHEkSUeb9Yz6XcDbgJ8f74AkW5JMkkwef/zxeWSTJDFDUSd5PXCwqnac6Liq2lZVS1W1dPHFa67UJ0k6DbOcUV8L3JRkH/AR4LokHxw1lSTpF05a1FV1W1VtqqpF4Gbg81X1xtGTSZIAr6OWpPZO6RNequpe4N5RkkiS1uQZtSQ1Z1FLUnMWtSQ1Z1FLUnMWtSQ1Z1FLUnMWtSQ1Z1FLUnMWtSQ1Z1FLUnMWtSQ1Z1FLUnMWtSQ1Z1FLUnOntMzprHYdWGZx6/Yxhh7Nvr9+3dmOIElr8oxakpqzqCWpOYtakpo7aVEnuTzJzlW3J5LcegaySZKY4cXEqtoLXAmQZAE4ANw1bixJ0opTnfq4Hnikqr49RhhJ0rFOtahvBm5f64kkW5JMkkwOH1r+5ZNJkoBTKOok5wM3AR9b6/mq2lZVS1W1tLBu/bzySdI571TOqG8EHqiq748VRpJ0rFMp6ls4zrSHJGk8MxV1knXAq4E7x40jSTraTGt9VNUh4IUjZ5EkrcF3JkpSc6Osnrd543omrkYnSXPhGbUkNWdRS1JzFrUkNWdRS1JzFrUkNWdRS1JzFrUkNWdRS1JzFrUkNWdRS1JzFrUkNWdRS1JzFrUkNTfK6nm7DiyzuHX7GEO3s89VAiWNzDNqSWrOopak5k5a1Enel+Rgkt1nIpAk6almOaP+F+CGkXNIko7jpEVdVV8E/vcMZJEkrWFuc9RJtiSZJJkcPrQ8r2El6Zw3t6Kuqm1VtVRVSwvr1s9rWEk653nVhyQ1Z1FLUnOzXJ53O/CfwOVJ9id5y/ixJEkrTvoW8qq65UwEkSStzakPSWpulEWZNm9cz8TFiiRpLjyjlqTmLGpJas6ilqTmLGpJas6ilqTmLGpJas6ilqTmLGpJas6ilqTmLGpJas6ilqTmLGpJas6ilqTmRlk9b9eBZRa3bh9jaI1kn6sdSm15Ri1JzVnUktTcTEWd5IYke5N8I8nWsUNJko6Y5cNtF4B/Am4ErgBuSXLF2MEkSVOznFFfDXyjqr5ZVT8BPgK8YdxYkqQVsxT1RuDRVY/3D/ueIsmWJJMkk8OHlueVT5LOebMUddbYV8fsqNpWVUtVtbSwbv0vn0ySBMxW1PuBS1Y93gQ8Nk4cSdLRZinqLwOXJbk0yfnAzcAnxo0lSVpx0ncmVtXPkvwp8BlgAXhfVT00ejJJEjDjW8ir6pPAJ0fOIklag+9MlKTmRlmUafPG9Uxc5EeS5sIzaklqzqKWpOYsaklqzqKWpOYsaklqzqKWpOYsaklqzqKWpOYsaklqzqKWpOYsaklqzqKWpOYsaklqbpTV83YdWGZx6/YxhtbTxD5XV5Rm5hm1JDVnUUtScxa1JDU30xx1kn3Ak8Bh4GdVtTRmKEnSEafyYuLvVtUPRksiSVqTUx+S1NysRV3AZ5PsSLJlrQOSbEkySTI5fGh5fgkl6Rw369THtVX1WJIXAfckebiqvrj6gKraBmwDeOaGy2rOOSXpnDXTGXVVPTbcHwTuAq4eM5Qk6YiTFnWSC5I8d2UbeA2we+xgkqSpWaY+XgzclWTl+A9X1adHTSVJ+oWTFnVVfRP49TOQRZK0hlEWZdq8cT0TF92RpLnwOmpJas6ilqTmLGpJas6ilqTmLGpJas6ilqTmLGpJas6ilqTmLGpJas6ilqTmLGpJas6ilqTmLGpJam6U1fN2HVhmcev2MYaWTmifqzbqacgzaklqzqKWpOYsaklqbpYPt70kyReS7EnyUJK3nolgkqSpWV5M/Bnwl1X1wPBp5DuS3FNVXxs5mySJGc6oq+q7VfXAsP0ksAfYOHYwSdLUKc1RJ1kErgLuW+O5LUkmSSaHDy3PKZ4kaeaiTvIc4OPArVX1xNHPV9W2qlqqqqWFdevnmVGSzmkzFXWS85iW9Ieq6s5xI0mSVpvlqo8A7wX2VNU7x48kSVptljPqa4E/AK5LsnO4vXbkXJKkwUkvz6uqLwE5A1kkSWvwnYmS1Nwoq+dt3rieiauYSdJceEYtSc1Z1JLUnEUtSc1Z1JLUnEUtSc1Z1JLUnEUtSc1Z1JLUnEUtSc1Z1JLUnEUtSc1Z1JLU3CiLMu06sMzi1u1jDC2pmX0uwDY6z6glqTmLWpKas6glqblZPtz2WUnuT/JgkoeSvONMBJMkTc3yYuL/AddV1Y+SnAd8Kcmnquq/Rs4mSWK2D7ct4EfDw/OGW40ZSpJ0xExz1EkWkuwEDgL3VNV9axyzJckkyeTwoeU5x5Skc9dMRV1Vh6vqSmATcHWSl61xzLaqWqqqpYV16+ccU5LOXad01UdV/RC4F7hhjDCSpGPNctXHxUkuHLafDbwKeHjkXJKkwSxXfWwAPpBkgWmxf7Sq7h43liRpxSxXfXwVuOoMZJEkrcF3JkpSc6Osnrd543omrqglSXPhGbUkNWdRS1JzFrUkNWdRS1JzFrUkNWdRS1JzFrUkNWdRS1JzFrUkNWdRS1JzFrUkNWdRS1JzoyzKtOvAMotbt48xtCS1tG/Eheg8o5ak5ixqSWrOopak5mYq6iQXJrkjycNJ9iS5ZuxgkqSpWV9M/Hvg01X1+0nOB9aNmEmStMpJizrJ84BXAm8GqKqfAD8ZN5YkacUsUx8vBR4H3p/kK0nek+SCow9KsiXJJMnk8KHluQeVpHPVLEX9DODlwLur6irgx8DWow+qqm1VtVRVSwvr1s85piSdu2Yp6v3A/qq6b3h8B9PiliSdASct6qr6HvBoksuHXdcDXxs1lSTpF2a96uPPgA8NV3x8E/ij8SJJklabqairaiewNG4USdJafGeiJDU3yup5mzeuZzLiSlKSdC7xjFqSmrOoJak5i1qSmrOoJak5i1qSmrOoJam5VNX8B02eBPbOfeD5uAj4wdkOcRxmOz2ds0HvfGY7PWNke0lVXbzWE6NcRw3sraqW72RMMjHbqTPb6eucz2yn50xnc+pDkpqzqCWpubGKettI486D2U6P2U5f53xmOz1nNNsoLyZKkubHqQ9Jas6ilqTm5lrUSW5IsjfJN5Ic8wG4Y0jyviQHk+xete8FSe5J8vXh/vmrnrttyLc3ye+t2v8bSXYNz/1Dkswh2yVJvpBkT5KHkry1S74kz0pyf5IHh2zv6JJt1bgLmX7y/d0Ns+0bxt2ZZNIpX5ILk9yR5OHhe++aDtmSXD78/1q5PZHk1g7ZhjH/fPhZ2J3k9uFnpEU2qmouN2ABeAR4KXA+8CBwxbzGP8HXfSXTD9vdvWrf3wJbh+2twN8M21cMuZ4JXDrkXRieux+4BgjwKeDGOWTbALx82H4u8N9DhrOebxjnOcP2ecB9wCs6ZFuV8S+ADwN3d/p7HcbdB1x01L4W+YAPAH88bJ8PXNgl26qMC8D3gJd0yAZsBL4FPHt4/FHgzR2yVdVci/oa4DOrHt8G3Dav8U/ytRd5alHvBTYM2xuYvgHnmEzAZ4bcG4CHV+2/BfjnEXL+O/DqbvmAdcADwG92yQZsAj4HXMeRom6RbRhrH8cW9VnPBzyPaeGkW7aj8rwG+I8u2ZgW9aPAC5i+EfDuIeNZz1ZVc536WPkPXbF/2Hc2vLiqvgsw3L9o2H+8jBuH7aP3z02SReAqpmeuLfINUws7gYPAPVXVJhvwLuBtwM9X7euSDaCAzybZkWRLo3wvBR4H3j9MG70nyQVNsq12M3D7sH3Ws1XVAeDvgO8A3wWWq+qzHbLBfOeo15qH6Xbt3/Eyjpo9yXOAjwO3VtUTJzr0ODlGyVdVh6vqSqZnr1cneVmHbEleDxysqh2z/pHjZBjz7/Xaqno5cCPwJ0leeYJjz2S+ZzCdCnx3VV0F/Jjpr+wdsk2/YHI+cBPwsZMdepwMY3zPPR94A9NpjF8FLkjyxg7ZYL5FvR+4ZNXjTcBjcxz/VHw/yQaA4f7gsP94GfcP20fv/6UlOY9pSX+oqu7slg+gqn4I3Avc0CTbtcBNSfYBHwGuS/LBJtkAqKrHhvuDwF3A1U3y7Qf2D78dAdzBtLg7ZFtxI/BAVX1/eNwh26uAb1XV41X1U+BO4LeaZJtrUX8ZuCzJpcO/mDcDn5jj+KfiE8Cbhu03MZ0bXtl/c5JnJrkUuAy4f/iV5skkrxheof3DVX/mtA1jvRfYU1Xv7JQvycVJLhy2n830G/XhDtmq6raq2lRVi0y/jz5fVW/skA0gyQVJnruyzXQuc3eHfFX1PeDRJJcPu64HvtYh2yq3cGTaYyXD2c72HeAVSdYNY14P7GmSbX4vJg4T569lemXDI8Db5zn2Cb7m7UznlH7K9F+ztwAvZPpC1NeH+xesOv7tQ769rHo1Flhi+sP2CPCPHPVizGlm+22mv/Z8Fdg53F7bIR/wa8BXhmy7gb8a9p/1bEfl/B2OvJjYIhvTeeAHh9tDK9/rjfJdCUyGv9t/A57fKNs64H+A9av2dcn2DqYnK7uBf2V6RUeLbL6FXJKa852JktScRS1JzVnUktScRS1JzVnUktScRS1JzVnUktTc/wM1aVr4R6hjBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapped_education = pd.Series(label_encoder.fit_transform(df[\"education\"]))\n",
    "mapped_education.value_counts().plot.barh()\n",
    "print(dict(enumerate(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "4658ebf0-6610-4c6f-88d0-3b1027a5c212",
    "_uuid": "68fba174918a7c498100b8bb2c4f9822a4c9a659"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>mon</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.961</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>131</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.864</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>tue</td>\n",
       "      <td>404</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.469</td>\n",
       "      <td>-33.6</td>\n",
       "      <td>1.044</td>\n",
       "      <td>5076.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nov</td>\n",
       "      <td>mon</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.191</td>\n",
       "      <td>5195.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education  default housing loan    contact  \\\n",
       "0   26      student   single          3       no      no   no  telephone   \n",
       "1   46       admin.  married          6       no     yes   no   cellular   \n",
       "2   49  blue-collar  married          0  unknown     yes  yes  telephone   \n",
       "3   31   technician  married          6       no      no   no   cellular   \n",
       "4   42    housemaid  married          6       no     yes   no  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  pdays  previous     poutcome  \\\n",
       "0   jun         mon       901         1    999         0  nonexistent   \n",
       "1   aug         tue       208         2    999         0  nonexistent   \n",
       "2   jun         tue       131         5    999         0  nonexistent   \n",
       "3   jul         tue       404         1    999         0  nonexistent   \n",
       "4   nov         mon        85         1    999         0  nonexistent   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
       "0           1.4          94.465          -41.8      4.961       5228.1  \n",
       "1           1.4          93.444          -36.1      4.963       5228.1  \n",
       "2           1.4          94.465          -41.8      4.864       5228.1  \n",
       "3          -2.9          92.469          -33.6      1.044       5076.2  \n",
       "4          -0.1          93.200          -42.0      4.191       5195.8  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"education\"] = mapped_education\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ead4109a-0bc3-476c-be13-59c152e0cb1c",
    "_uuid": "4c02df6d2afbcd5a47d591004fe9a068e95ecb65"
   },
   "source": [
    "Let's apply the transformation to other columns of type `object`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "f6b6056e-3823-4caf-a617-d99ab490512d",
    "_uuid": "8079ecf58d4fa138d92c21f46b001cb3ed050a0a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.961</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>131</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.864</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>404</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.469</td>\n",
       "      <td>-33.6</td>\n",
       "      <td>1.044</td>\n",
       "      <td>5076.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.191</td>\n",
       "      <td>5195.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  housing  loan  contact  month  \\\n",
       "0   26    8        2          3        0        0     0        1      4   \n",
       "1   46    0        1          6        0        2     0        0      1   \n",
       "2   49    1        1          0        1        2     2        1      4   \n",
       "3   31    9        1          6        0        0     0        0      3   \n",
       "4   42    3        1          6        0        2     0        1      7   \n",
       "\n",
       "   day_of_week  duration  campaign  pdays  previous  poutcome  emp.var.rate  \\\n",
       "0            1       901         1    999         0         1           1.4   \n",
       "1            3       208         2    999         0         1           1.4   \n",
       "2            3       131         5    999         0         1           1.4   \n",
       "3            3       404         1    999         0         1          -2.9   \n",
       "4            1        85         1    999         0         1          -0.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
       "0          94.465          -41.8      4.961       5228.1  \n",
       "1          93.444          -36.1      4.963       5228.1  \n",
       "2          94.465          -41.8      4.864       5228.1  \n",
       "3          92.469          -33.6      1.044       5076.2  \n",
       "4          93.200          -42.0      4.191       5195.8  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = df.columns[df.dtypes == \"object\"].union([\"education\"])\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a79eddaa-26d4-4316-a4d9-ce1a8f024e65",
    "_uuid": "89931fdf8b27f8e8ba8be53dc33368dc1dc3ad46"
   },
   "source": [
    "The main issue with this approach is that we have now introduced some relative ordering where it might not exist.  \n",
    "\n",
    "For example, we implicitly introduced algebra over the values of the job feature where we can now substract the job of client #2 from the job of client #1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "9e85d727-a23c-4fda-859e-9cfa2491b044",
    "_uuid": "10efbea02831df6e1e8476a8813aedd227f9d4ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1].job - df.loc[2].job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "16ea6d8f-8d03-427b-a9f8-f8827cb9b629",
    "_uuid": "f91a2a86a06fb9b36dd932d4afb08dc7c178983f"
   },
   "source": [
    "Does this operation make any sense? Not really. Let's try to train logisitic regression with this feature transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "7dede4d6-e787-4232-a1ac-01191a88ec88",
    "_uuid": "15c8fdb284d4e5166f3f56c4e9d8f1810186ff7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6176\n",
      "           1       1.00      0.00      0.01       723\n",
      "\n",
      "    accuracy                           0.90      6899\n",
      "   macro avg       0.95      0.50      0.48      6899\n",
      "weighted avg       0.91      0.90      0.85      6899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression_accuracy_on(dataframe, labels):\n",
    "    features = dataframe\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features, labels\n",
    "    )\n",
    "\n",
    "    logit = LogisticRegression()\n",
    "    logit.fit(train_features, train_labels)\n",
    "    return classification_report(test_labels, logit.predict(test_features))\n",
    "\n",
    "\n",
    "print(logistic_regression_accuracy_on(df[categorical_columns], labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7ac2b754-b7e9-4bed-b90e-d27db1b72b01",
    "_uuid": "b2982316ff21f4585188cbb6987df0114cbe4b3f"
   },
   "source": [
    "We can see that logistic regression never predicts class 1. In order to use linear models with categorical features, we will use a different approach: One-Hot Encoding.\n",
    "\n",
    "### 2.2. One-Hot Encoding\n",
    "\n",
    "Suppose that some feature can have one of 10 unique values. One-hot encoding creates 10 new features corresponding to these unique values, all of them *except one* are zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "df17447f-6ff8-4342-b755-c856fb1c7bd6",
    "_uuid": "6ca824f36f66c8e6889688e8f64c2ca6ec7605df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9\n",
       "0  0  0  0  0  0  0  1  0  0  0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_example = pd.DataFrame([{i: 0 for i in range(10)}])\n",
    "one_hot_example.loc[0, 6] = 1\n",
    "one_hot_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f4c2d551-d511-4b6a-a161-e80b167b6607",
    "_uuid": "ea9c96c96b528b9fda95fb0ebc53089e05de3a58"
   },
   "source": [
    "This idea is implemented in the `OneHotEncoder` class from `sklearn.preprocessing`. By default `OneHotEncoder` transforms data into a sparse matrix to save memory space because most of the values are zeroes and because we do not want to take up more RAM. However, in this particular example, we do not encounter such problems, so we are going to use a \"dense\" matrix representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "29d1f40e-cfb4-4ee0-b9ee-8c779b7c803b",
    "_uuid": "fa7ad1f51154182f467a5df5dd7d43ec111132b8"
   },
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "0d70a254-f732-40c9-b738-67ca6b8d2d24",
    "_uuid": "ecfb22058b460d751779df0f9492928a317914de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   43   44   45   46  \\\n",
       "0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "1  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "3  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  1.0  0.0  0.0  0.0   \n",
       "4  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    47   48   49   50   51   52  \n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "4  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_categorical_columns = pd.DataFrame(\n",
    "    onehot_encoder.fit_transform(df[categorical_columns])\n",
    ")\n",
    "encoded_categorical_columns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9db91f18-2a19-4c54-ae15-34cc7df16216",
    "_uuid": "0c162f2cc7d813cef43971aec666aaccc2aaa7b8"
   },
   "source": [
    "We have 53 columns that correspond to the number of unique values of categorical features in our data set. When transformed with One-Hot Encoding, this data can be used with linear models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "84c611df-8c2e-45dc-a108-aab6bf39a530",
    "_uuid": "cebd716350bc29dabb07f797db16e693fa92a76a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6104\n",
      "           1       0.67      0.16      0.25       795\n",
      "\n",
      "    accuracy                           0.89      6899\n",
      "   macro avg       0.79      0.57      0.60      6899\n",
      "weighted avg       0.87      0.89      0.86      6899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(logistic_regression_accuracy_on(encoded_categorical_columns, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "361416b2-4279-434a-98bf-82f79de11f3d",
    "_uuid": "e7976bb1de18e2f63e78c9e7ec72266ca158b9c1"
   },
   "source": [
    "### 2.3. Hashing trick\n",
    "Real data can be volatile, meaning we cannot guarantee that new values of categorical features will not occur. This issue hampers using a trained model on new data. Besides that, `LabelEncoder` requires preliminary analysis of the whole dataset and storage of constructed mappings in memory, which makes it difficult to work with large datasets.\n",
    "\n",
    "There is a simple approach to vectorization of categorical data based on hashing and is known as, not-so-surprisingly, the hashing trick. \n",
    "\n",
    "Hash functions can help us find unique codes for different feature values, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "d9eb2e54-18e7-4056-8f28-f22a044596d8",
    "_uuid": "01064911e1e0af0b3829b0e0be2a965aa3e8eb3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "university.degree -> -1072856226840532349\n",
      "high.school -> -4503594350187779020\n",
      "illiterate -> -8457341022589043141\n"
     ]
    }
   ],
   "source": [
    "for s in (\"university.degree\", \"high.school\", \"illiterate\"):\n",
    "    print(s, \"->\", hash(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "381e8137-cf66-418c-835a-84b5882cfdc2",
    "_uuid": "b93b5bcf1a9ad4a2dc92704bab63f831ea5e19bf"
   },
   "source": [
    "We will not use negative values or values of high magnitude, so we restrict the range of values for the hash function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "943fc564-80f0-4350-980a-cce6c6a2e7cd",
    "_uuid": "b92f7eabc498b8339abed0f8fd400bba5750209a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "university.degree -> 1\n",
      "high.school -> 5\n",
      "illiterate -> 9\n"
     ]
    }
   ],
   "source": [
    "hash_space = 25\n",
    "for s in (\"university.degree\", \"high.school\", \"illiterate\"):\n",
    "    print(s, \"->\", hash(s) % hash_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae21a334-e53f-4cb1-abfc-fa7ed35ba1ae",
    "_uuid": "6eda4bc3ccce5ca01700bc95878fc4996b7aabaa"
   },
   "source": [
    "Imagine that our data set contains a single (i.e. not married) student, who received a call on Monday. His feature vectors will be created similarly as in the case of One-Hot Encoding but in the space with fixed range for all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "c94253b2-3981-4bbd-817f-96c3f660d464",
    "_uuid": "af62a2ed3770a537bc3168d0a06c6d20b737f887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job=student -> 2\n",
      "marital=single -> 5\n",
      "day_of_week=mon -> 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   15   16   17   18  \\\n",
       "0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    19   20   21   22   23   24  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashing_example = pd.DataFrame([{i: 0.0 for i in range(hash_space)}])\n",
    "for s in (\"job=student\", \"marital=single\", \"day_of_week=mon\"):\n",
    "    print(s, \"->\", hash(s) % hash_space)\n",
    "    hashing_example.loc[0, hash(s) % hash_space] = 1\n",
    "hashing_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4913a8ad-2ecc-4f50-b887-f19b51afdd01",
    "_uuid": "51d6391d6c180365161865070a0ebf589d2a344e"
   },
   "source": [
    "We want to point out that we hash not only feature values but also pairs of **feature name + feature value**. It is important to do this so that we can distinguish the same values of different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "48540748-405a-413d-ac0c-5aa0422b9087",
    "_uuid": "e025f8486b3091090e93c27c082145b5f3e11967"
   },
   "outputs": [],
   "source": [
    "assert hash(\"no\") == hash(\"no\")\n",
    "assert hash(\"housing=no\") != hash(\"loan=no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bfb6bdc6-9593-4a8f-a961-24221567c70f",
    "_uuid": "4ec7bcce511995a7d71a6542bbd71c9086f8f9e0"
   },
   "source": [
    "Is it possible to have a collision when using hash codes? Sure, it is possible, but it is a rare case with large enough hashing spaces. Even if collision occurs, regression or classification metrics will not suffer much. In this case, hash collisions work as a form of regularization.\n",
    "\n",
    "\n",
    "<img src=\"https://habrastorage.org/webt/4o/wx/59/4owx59vdvwc9mzrf81t2fa2rqrc.jpeg\">\n",
    "\n",
    "You may be saying \"WTF?\"; hashing seems counterintuitive. This is true, but these heuristics sometimes are, in fact, the only plausible approach to work with categorical data (what else can you do if you have 30M features?). Moreover, this technique has proven to just work. As you work more with data, you may see this for yourself.\n",
    "\n",
    "A good analysis of hash collisions, their dependency on feature space and hashing space dimensions and affecting classification/regression performance is done in [this article](https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087) by Booking.com. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d2361062-61d9-4dd6-bac2-cbf2bd0ccebb",
    "_uuid": "1a565b5d7413123af2b5997cd9f74266187effca"
   },
   "source": [
    "## 3. Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e6a2e0f9-785e-4cf6-9013-b114099daddd",
    "_uuid": "01e502198f14273eadcab0f10e090ddbaba07b87"
   },
   "source": [
    "[Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit) (VW) is one of the most widespread machine learning libraries used in industry. It is prominent for its training speed and support of many training modes, especially for online learning with big and high-dimentional data. This is one of the major merits of the library. Also, with the hashing trick implemented, Vowpal Wabbit is a perfect choice for working with text data.\n",
    "\n",
    "Shell is the main interface for VW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "24fd028f-416e-43ff-9530-5c8f47bde176",
    "_uuid": "4cc17ec6551c7e7dcf224a3b03794720d90cb966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num weight bits = 18\r\n",
      "learning rate = 0.5\r\n",
      "initial_t = 0\r\n",
      "power_t = 0.5\r\n",
      "using no cache\r\n",
      "Reading datafile = \r\n",
      "num sources = 1\r\n",
      "driver:\r\n",
      "  --onethread           Disable parse thread\r\n",
      "VW options:\r\n",
      "  --ring_size arg (=256, ) size of example ring\r\n",
      "  --strict_parse           throw on malformed examples\r\n",
      "Update options:\r\n",
      "  -l [ --learning_rate ] arg Set learning rate\r\n",
      "  --power_t arg              t power value\r\n",
      "  --decay_learning_rate arg  Set Decay factor for learning_rate between passes\r\n",
      "  --initial_t arg            initial t value\r\n",
      "  --feature_mask arg         Use existing regressor to determine which \r\n",
      "                             parameters may be updated.  If no \r\n",
      "                             initial_regressor given, also used for initial \r\n",
      "                             weights.\r\n",
      "Weight options:\r\n",
      "  -i [ --initial_regressor ] arg  Initial regressor(s)\r\n",
      "  --initial_weight arg            Set all weights to an initial value of arg.\r\n",
      "  --random_weights                make initial weights random\r\n",
      "  --normal_weights                make initial weights normal\r\n",
      "  --truncated_normal_weights      make initial weights truncated normal\r\n",
      "  --sparse_weights                Use a sparse datastructure for weights\r\n",
      "  --input_feature_regularizer arg Per feature regularization input file\r\n",
      "Parallelization options:\r\n",
      "  --span_server arg                 Location of server for setting up spanning \r\n",
      "                                    tree\r\n",
      "  --unique_id arg (=0, )            unique id used for cluster parallel jobs\r\n",
      "  --total arg (=1, )                total number of nodes used in cluster \r\n",
      "                                    parallel job\r\n",
      "  --node arg (=0, )                 node number in cluster parallel job\r\n",
      "  --span_server_port arg (=26543, ) Port of the server for setting up spanning \r\n",
      "                                    tree\r\n",
      "Diagnostic options:\r\n",
      "  --version             Version information\r\n",
      "  -a [ --audit ]        print weights of features\r\n",
      "  -P [ --progress ] arg Progress update frequency. int: additive, float: \r\n",
      "                        multiplicative\r\n",
      "  --quiet               Don't output disgnostics and progress updates\r\n",
      "  -h [ --help ]         Look here: http://hunch.net/~vw/ and click on Tutorial.\r\n",
      "Randomization options:\r\n",
      "  --random_seed arg     seed random number generator\r\n",
      "Feature options:\r\n",
      "  --hash arg                      how to hash the features. Available options: \r\n",
      "                                  strings, all\r\n",
      "  --hash_seed arg (=0, )          seed for hash function\r\n",
      "  --ignore arg                    ignore namespaces beginning with character \r\n",
      "                                  <arg>\r\n",
      "  --ignore_linear arg             ignore namespaces beginning with character \r\n",
      "                                  <arg> for linear terms only\r\n",
      "  --keep arg                      keep namespaces beginning with character \r\n",
      "                                  <arg>\r\n",
      "  --redefine arg                  redefine namespaces beginning with characters\r\n",
      "                                  of std::string S as namespace N. <arg> shall \r\n",
      "                                  be in form 'N:=S' where := is operator. Empty\r\n",
      "                                  N or S are treated as default namespace. Use \r\n",
      "                                  ':' as a wildcard in S.\r\n",
      "  -b [ --bit_precision ] arg      number of bits in the feature table\r\n",
      "  --noconstant                    Don't add a constant feature\r\n",
      "  -C [ --constant ] arg           Set initial value of constant\r\n",
      "  --ngram arg                     Generate N grams. To generate N grams for a \r\n",
      "                                  single namespace 'foo', arg should be fN.\r\n",
      "  --skips arg                     Generate skips in N grams. This in \r\n",
      "                                  conjunction with the ngram tag can be used to\r\n",
      "                                  generate generalized n-skip-k-gram. To \r\n",
      "                                  generate n-skips for a single namespace \r\n",
      "                                  'foo', arg should be fN.\r\n",
      "  --feature_limit arg             limit to N features. To apply to a single \r\n",
      "                                  namespace 'foo', arg should be fN\r\n",
      "  --affix arg                     generate prefixes/suffixes of features; \r\n",
      "                                  argument '+2a,-3b,+1' means generate 2-char \r\n",
      "                                  prefixes for namespace a, 3-char suffixes for\r\n",
      "                                  b and 1 char prefixes for default namespace\r\n",
      "  --spelling arg                  compute spelling features for a give \r\n",
      "                                  namespace (use '_' for default namespace)\r\n",
      "  --dictionary arg                read a dictionary for additional features \r\n",
      "                                  (arg either 'x:file' or just 'file')\r\n",
      "  --dictionary_path arg           look in this directory for dictionaries; \r\n",
      "                                  defaults to current directory or env{PATH}\r\n",
      "  --interactions arg              Create feature interactions of any level \r\n",
      "                                  between namespaces.\r\n",
      "  --permutations                  Use permutations instead of combinations for \r\n",
      "                                  feature interactions of same namespace.\r\n",
      "  --leave_duplicate_interactions  Don't remove interactions with duplicate \r\n",
      "                                  combinations of namespaces. For ex. this is a\r\n",
      "                                  duplicate: '-q ab -q ba' and a lot more in \r\n",
      "                                  '-q ::'.\r\n",
      "  -q [ --quadratic ] arg          Create and use quadratic features\r\n",
      "  --q: arg                        DEPRECATED ':' corresponds to a wildcard for \r\n",
      "                                  all printable characters\r\n",
      "  --cubic arg                     Create and use cubic features\r\n",
      "Example options:\r\n",
      "  -t [ --testonly ]                Ignore label information and just test\r\n",
      "  --holdout_off                    no holdout data in multiple passes\r\n",
      "  --holdout_period arg (=10, )     holdout period for test only\r\n",
      "  --holdout_after arg              holdout after n training examples, default \r\n",
      "                                   off (disables holdout_period)\r\n",
      "  --early_terminate arg (=3, )     Specify the number of passes tolerated when \r\n",
      "                                   holdout loss doesn't decrease before early \r\n",
      "                                   termination\r\n",
      "  --passes arg                     Number of Training Passes\r\n",
      "  --initial_pass_length arg        initial number of examples per pass\r\n",
      "  --examples arg                   number of examples to parse\r\n",
      "  --min_prediction arg             Smallest prediction to output\r\n",
      "  --max_prediction arg             Largest prediction to output\r\n",
      "  --sort_features                  turn this on to disregard order in which \r\n",
      "                                   features have been defined. This will lead \r\n",
      "                                   to smaller cache sizes\r\n",
      "  --loss_function arg (=squared, ) Specify the loss function to be used, uses \r\n",
      "                                   squared by default. Currently available ones\r\n",
      "                                   are squared, classic, hinge, logistic, \r\n",
      "                                   quantile and poisson.\r\n",
      "  --quantile_tau arg (=0.5, )      Parameter \\tau associated with Quantile \r\n",
      "                                   loss. Defaults to 0.5\r\n",
      "  --l1 arg                         l_1 lambda\r\n",
      "  --l2 arg                         l_2 lambda\r\n",
      "  --no_bias_regularization         no bias in regularization\r\n",
      "  --named_labels arg               use names for labels (multiclass, etc.) \r\n",
      "                                   rather than integers, argument specified all\r\n",
      "                                   possible labels, comma-sep, eg \r\n",
      "                                   \"--named_labels Noun,Verb,Adj,Punc\"\r\n",
      "Output model:\r\n",
      "  -f [ --final_regressor ] arg          Final regressor\r\n",
      "  --readable_model arg                  Output human-readable final regressor \r\n",
      "                                        with numeric features\r\n",
      "  --invert_hash arg                     Output human-readable final regressor \r\n",
      "                                        with feature names.  Computationally \r\n",
      "                                        expensive.\r\n",
      "  --save_resume                         save extra state so learning can be \r\n",
      "                                        resumed later with new data\r\n",
      "  --preserve_performance_counters       reset performance counters when \r\n",
      "                                        warmstarting\r\n",
      "  --save_per_pass                       Save the model after every pass over \r\n",
      "                                        data\r\n",
      "  --output_feature_regularizer_binary arg\r\n",
      "                                        Per feature regularization output file\r\n",
      "  --output_feature_regularizer_text arg Per feature regularization output file,\r\n",
      "                                        in text\r\n",
      "  --id arg                              User supplied ID embedded into the \r\n",
      "                                        final regressor\r\n",
      "Output options:\r\n",
      "  -p [ --predictions ] arg     File to output predictions to\r\n",
      "  -r [ --raw_predictions ] arg File to output unnormalized predictions to\r\n",
      "Audit Regressor:\r\n",
      "  --audit_regressor arg stores feature names and their regressor values. Same \r\n",
      "                        dataset must be used for both regressor training and \r\n",
      "                        this mode.\r\n",
      "Search options:\r\n",
      "  --search arg                          Use learning to search, \r\n",
      "                                        argument=maximum action id or 0 for LDF\r\n",
      "  --search_task arg                     the search task (use \"--search_task \r\n",
      "                                        list\" to get a list of available tasks)\r\n",
      "  --search_metatask arg                 the search metatask (use \r\n",
      "                                        \"--search_metatask list\" to get a list \r\n",
      "                                        of available metatasks)\r\n",
      "  --search_interpolation arg            at what level should interpolation \r\n",
      "                                        happen? [*data|policy]\r\n",
      "  --search_rollout arg                  how should rollouts be executed?       \r\n",
      "                                            [policy|oracle|*mix_per_state|mix_p\r\n",
      "                                        er_roll|none]\r\n",
      "  --search_rollin arg                   how should past trajectories be \r\n",
      "                                        generated? [policy|oracle|*mix_per_stat\r\n",
      "                                        e|mix_per_roll]\r\n",
      "  --search_passes_per_policy arg (=1, ) number of passes per policy (only valid\r\n",
      "                                        for search_interpolation=policy)\r\n",
      "  --search_beta arg (=0.5, )            interpolation rate for policies (only \r\n",
      "                                        valid for search_interpolation=policy)\r\n",
      "  --search_alpha arg (=1e-10, )         annealed beta = 1-(1-alpha)^t (only \r\n",
      "                                        valid for search_interpolation=data)\r\n",
      "  --search_total_nb_policies arg        if we are going to train the policies \r\n",
      "                                        through multiple separate calls to vw, \r\n",
      "                                        we need to specify this parameter and \r\n",
      "                                        tell vw how many policies are \r\n",
      "                                        eventually going to be trained\r\n",
      "  --search_trained_nb_policies arg      the number of trained policies in a \r\n",
      "                                        file\r\n",
      "  --search_allowed_transitions arg      read file of allowed transitions [def: \r\n",
      "                                        all transitions are allowed]\r\n",
      "  --search_subsample_time arg           instead of training at all timesteps, \r\n",
      "                                        use a subset. if value in (0,1), train \r\n",
      "                                        on a random v%. if v>=1, train on \r\n",
      "                                        precisely v steps per example, if \r\n",
      "                                        v<=-1, use active learning\r\n",
      "  --search_neighbor_features arg        copy features from neighboring lines. \r\n",
      "                                        argument looks like: '-1:a,+2' meaning \r\n",
      "                                        copy previous line namespace a and next\r\n",
      "                                        next line from namespace _unnamed_, \r\n",
      "                                        where ',' separates them\r\n",
      "  --search_rollout_num_steps arg        how many calls of \"loss\" before we stop\r\n",
      "                                        really predicting on rollouts and \r\n",
      "                                        switch to oracle (default means \r\n",
      "                                        \"infinite\")\r\n",
      "  --search_history_length arg (=1, )    some tasks allow you to specify how \r\n",
      "                                        much history their depend on; specify \r\n",
      "                                        that here\r\n",
      "  --search_no_caching                   turn off the built-in caching ability \r\n",
      "                                        (makes things slower, but technically \r\n",
      "                                        more safe)\r\n",
      "  --search_xv                           train two separate policies, \r\n",
      "                                        alternating prediction/learning\r\n",
      "  --search_perturb_oracle arg (=0, )    perturb the oracle on rollin with this \r\n",
      "                                        probability\r\n",
      "  --search_linear_ordering              insist on generating examples in linear\r\n",
      "                                        order (def: hoopla permutation)\r\n",
      "  --search_active_verify arg            verify that active learning is doing \r\n",
      "                                        the right thing (arg = multiplier, \r\n",
      "                                        should be = cost_range * range_c)\r\n",
      "  --search_save_every_k_runs arg        save model every k runs\r\n",
      "Experience Replay:\r\n",
      "  --replay_c arg              use experience replay at a specified level \r\n",
      "                              [b=classification/regression, m=multiclass, \r\n",
      "                              c=cost sensitive] with specified buffer size\r\n",
      "  --replay_c_count arg (=1, ) how many times (in expectation) should each \r\n",
      "                              example be played (default: 1 = permuting)\r\n",
      "Explore evaluation:\r\n",
      "  --explore_eval        Evaluate explore_eval adf policies\r\n",
      "  --multiplier arg      Multiplier used to make all rejection sample \r\n",
      "                        probabilities <= 1\r\n",
      "Make csoaa_ldf into Contextual Bandit:\r\n",
      "  --cbify_ldf           Convert csoaa_ldf into a contextual bandit problem\r\n",
      "  --loss0 arg (=0, )    loss for correct label\r\n",
      "  --loss1 arg (=1, )    loss for incorrect label\r\n",
      "Make Multiclass into Contextual Bandit:\r\n",
      "  --cbify arg           Convert multiclass on <k> classes into a contextual \r\n",
      "                        bandit problem\r\n",
      "  --cbify_cs            consume cost-sensitive classification examples instead \r\n",
      "                        of multiclass\r\n",
      "  --loss0 arg (=0, )    loss for correct label\r\n",
      "  --loss1 arg (=1, )    loss for incorrect label\r\n",
      "Make Multiclass into Warm-starting Contextual Bandit:\r\n",
      "  --warm_cb arg                        Convert multiclass on <k> classes into a\r\n",
      "                                       contextual bandit problem\r\n",
      "  --warm_cb_cs                         consume cost-sensitive classification \r\n",
      "                                       examples instead of multiclass\r\n",
      "  --loss0 arg (=0, )                   loss for correct label\r\n",
      "  --loss1 arg (=1, )                   loss for incorrect label\r\n",
      "  --warm_start arg (=0, )              number of training examples for warm \r\n",
      "                                       start phase\r\n",
      "  --epsilon arg                        epsilon-greedy exploration\r\n",
      "  --interaction arg (=4294967295, )    number of examples for the interactive \r\n",
      "                                       contextual bandit learning phase\r\n",
      "  --warm_start_update                  indicator of warm start updates\r\n",
      "  --interaction_update                 indicator of interaction updates\r\n",
      "  --corrupt_type_warm_start arg (=1, ) type of label corruption in the warm \r\n",
      "                                       start phase (1: uniformly at random, 2: \r\n",
      "                                       circular, 3: replacing with overwriting \r\n",
      "                                       label)\r\n",
      "  --corrupt_prob_warm_start arg (=0, ) probability of label corruption in the \r\n",
      "                                       warm start phase\r\n",
      "  --choices_lambda arg (=1, )          the number of candidate lambdas to \r\n",
      "                                       aggregate (lambda is the importance \r\n",
      "                                       weight parameter between the two \r\n",
      "                                       sources)\r\n",
      "  --lambda_scheme arg (=1, )           The scheme for generating candidate \r\n",
      "                                       lambda set (1: center lambda=0.5, 2: \r\n",
      "                                       center lambda=0.5, min lambda=0, max \r\n",
      "                                       lambda=1, 3: center lambda=epsilon/(1+ep\r\n",
      "                                       silon), 4: center lambda=epsilon/(1+epsi\r\n",
      "                                       lon), min lambda=0, max lambda=1); the \r\n",
      "                                       rest of candidate lambda values are \r\n",
      "                                       generated using a doubling scheme\r\n",
      "  --overwrite_label arg (=1, )         the label used by type 3 corruptions \r\n",
      "                                       (overwriting)\r\n",
      "  --sim_bandit                         simulate contextual bandit updates on \r\n",
      "                                       warm start examples\r\n",
      "Slates:\r\n",
      "  --slates              EXPERIMENTAL\r\n",
      "EXPERIMENTAL: Conditional Contextual Bandit Exploration with Action Dependent Features:\r\n",
      "  --ccb_explore_adf     EXPERIMENTAL: Do Conditional Contextual Bandit learning\r\n",
      "                        with multiline action dependent features.\r\n",
      "CB Sample:\r\n",
      "  --cb_sample           Sample from CB pdf and swap top action.\r\n",
      "CB Distributionally Robust Optimization:\r\n",
      "  --cb_dro                     Use DRO for cb learning\r\n",
      "  --cb_dro_alpha arg (=0.05, ) Confidence level for cb dro\r\n",
      "  --cb_dro_tau arg (=0.999, )  Time constant for count decay for cb dro\r\n",
      "  --cb_dro_wmax arg (=inf, )   maximum importance weight for cb_dro\r\n",
      "Contextual Bandit Exploration with Action Dependent Features:\r\n",
      "  --cb_explore_adf      Online explore-exploit for a contextual bandit problem \r\n",
      "                        with multiline action dependent features\r\n",
      "  --epsilon arg         epsilon-greedy exploration\r\n",
      "  --bag arg             bagging-based exploration\r\n",
      "  --greedify            always update first policy once in bagging\r\n",
      "  --first_only          Only explore the first action in a tie-breaking event\r\n",
      "Contextual Bandit Exploration with Action Dependent Features:\r\n",
      "  --cb_explore_adf      Online explore-exploit for a contextual bandit problem \r\n",
      "                        with multiline action dependent features\r\n",
      "  --cover arg           Online cover based exploration\r\n",
      "  --psi arg (=1, )      disagreement parameter for cover\r\n",
      "  --nounif              do not explore uniformly on zero-probability actions in\r\n",
      "                        cover\r\n",
      "  --first_only          Only explore the first action in a tie-breaking event\r\n",
      "  --cb_type arg         contextual bandit method to use in {ips,dr,mtr}. \r\n",
      "                        Default: mtr\r\n",
      "Contextual Bandit Exploration with Action Dependent Features:\r\n",
      "  --cb_explore_adf      Online explore-exploit for a contextual bandit problem \r\n",
      "                        with multiline action dependent features\r\n",
      "  --first arg           tau-first exploration\r\n",
      "  --epsilon arg         epsilon-greedy exploration\r\n",
      "Contextual Bandit Exploration with Action Dependent Features:\r\n",
      "  --cb_explore_adf          Online explore-exploit for a contextual bandit \r\n",
      "                            problem with multiline action dependent features\r\n",
      "  --regcb                   RegCB-elim exploration\r\n",
      "  --regcbopt                RegCB optimistic exploration\r\n",
      "  --mellowness arg (=0.1, ) RegCB mellowness parameter c_0. Default 0.1\r\n",
      "  --cb_min_cost arg (=0, )  lower bound on cost\r\n",
      "  --cb_max_cost arg (=1, )  upper bound on cost\r\n",
      "  --first_only              Only explore the first action in a tie-breaking \r\n",
      "                            event\r\n",
      "  --cb_type arg             contextual bandit method to use in {ips,dr,mtr}. \r\n",
      "                            Default: mtr\r\n",
      "Contextual Bandit Exploration with Action Dependent Features:\r\n",
      "  --cb_explore_adf             Online explore-exploit for a contextual bandit \r\n",
      "                               problem with multiline action dependent features\r\n",
      "  --epsilon arg                minimum exploration probability\r\n",
      "  --rnd arg                    rnd based exploration\r\n",
      "  --rnd_alpha arg (=0.1, )     ci width for rnd (bigger => more exploration on \r\n",
      "                               repeating features)\r\n",
      "  --rnd_invlambda arg (=0.1, ) covariance regularization strength rnd (bigger \r\n",
      "                               => more exploration on new features)\r\n",
      "Contextual Bandit Exploration with Action Dependent Features:\r\n",
      "  --cb_explore_adf      Online explore-exploit for a contextual bandit problem \r\n",
      "                        with multiline action dependent features\r\n",
      "  --epsilon arg         epsilon-greedy exploration\r\n",
      "  --softmax             softmax exploration\r\n",
      "  --lambda arg (=1, )   parameter for softmax\r\n",
      "Contextual Bandit Exploration with Action Dependent Features:\r\n",
      "  --cb_explore_adf      Online explore-exploit for a contextual bandit problem \r\n",
      "                        with multiline action dependent features\r\n",
      "  --epsilon arg         epsilon-greedy exploration\r\n",
      "  --first_only          Only explore the first action in a tie-breaking event\r\n",
      "Contextual Bandit Exploration:\r\n",
      "  --cb_explore arg        Online explore-exploit for a <k> action contextual \r\n",
      "                          bandit problem\r\n",
      "  --first arg             tau-first exploration\r\n",
      "  --epsilon arg (=0.05, ) epsilon-greedy exploration\r\n",
      "  --bag arg               bagging-based exploration\r\n",
      "  --cover arg             Online cover based exploration\r\n",
      "  --psi arg (=1, )        disagreement parameter for cover\r\n",
      "Multiworld Testing Options:\r\n",
      "  --multiworld_test arg Evaluate features as a policies\r\n",
      "  --learn arg           Do Contextual Bandit learning on <n> classes.\r\n",
      "  --exclude_eval        Discard mwt policy features before learning\r\n",
      "Contextual Bandit with Action Dependent Features:\r\n",
      "  --cb_adf              Do Contextual Bandit learning with multiline action \r\n",
      "                        dependent features.\r\n",
      "  --rank_all            Return actions sorted by score order\r\n",
      "  --no_predict          Do not do a prediction when training\r\n",
      "  --clip_p arg (=0, )   Clipping probability in importance weight. Default: 0.f\r\n",
      "                        (no clipping).\r\n",
      "  --cb_type arg         contextual bandit method to use in {ips, dm, dr, mtr, \r\n",
      "                        sm}. Default: mtr\r\n",
      "Contextual Bandit Options:\r\n",
      "  --cb arg              Use contextual bandit learning with <k> costs\r\n",
      "  --cb_type arg         contextual bandit method to use in {ips,dm,dr}\r\n",
      "  --eval                Evaluate a policy rather than optimizing.\r\n",
      "Cost Sensitive One Against All with Label Dependent Features:\r\n",
      "  --csoaa_ldf arg       Use one-against-all multiclass learning with label \r\n",
      "                        dependent features.\r\n",
      "  --ldf_override arg    Override singleline or multiline from csoaa_ldf or \r\n",
      "                        wap_ldf, eg if stored in file\r\n",
      "  --csoaa_rank          Return actions sorted by score order\r\n",
      "  --probabilities       predict probabilites of all classes\r\n",
      "Cost Sensitive One Against All with Label Dependent Features:\r\n",
      "  --wap_ldf arg         Use weighted all-pairs multiclass learning with label \r\n",
      "                        dependent features.  Specify singleline or multiline.\r\n",
      "Interact via elementwise multiplication:\r\n",
      "  --interact arg        Put weights on feature products from namespaces <n1> \r\n",
      "                        and <n2>\r\n",
      "Cost Sensitive One Against All:\r\n",
      "  --csoaa arg           One-against-all multiclass with <k> costs\r\n",
      "Cost-sensitive Active Learning:\r\n",
      "  --cs_active arg                       Cost-sensitive active learning with <k>\r\n",
      "                                        costs\r\n",
      "  --simulation                          cost-sensitive active learning \r\n",
      "                                        simulation mode\r\n",
      "  --baseline                            cost-sensitive active learning baseline\r\n",
      "  --domination arg (=1, )               cost-sensitive active learning use \r\n",
      "                                        domination. Default 1\r\n",
      "  --mellowness arg (=0.1, )             mellowness parameter c_0. Default 0.1.\r\n",
      "  --range_c arg (=0.5, )                parameter controlling the threshold for\r\n",
      "                                        per-label cost uncertainty. Default \r\n",
      "                                        0.5.\r\n",
      "  --max_labels arg (=18446744073709551615, )\r\n",
      "                                        maximum number of label queries.\r\n",
      "  --min_labels arg (=18446744073709551615, )\r\n",
      "                                        minimum number of label queries.\r\n",
      "  --cost_max arg (=1, )                 cost upper bound. Default 1.\r\n",
      "  --cost_min arg (=0, )                 cost lower bound. Default 0.\r\n",
      "  --csa_debug                           print debug stuff for cs_active\r\n",
      "Multilabel One Against All:\r\n",
      "  --multilabel_oaa arg  One-against-all multilabel with <k> labels\r\n",
      "importance weight classes:\r\n",
      "  --classweight arg     importance weight multiplier for class\r\n",
      "Memory Tree:\r\n",
      "  --memory_tree arg (=0, )             Make a memory tree with at most <n> \r\n",
      "                                       nodes\r\n",
      "  --max_number_of_labels arg (=10, )   max number of unique label\r\n",
      "  --leaf_example_multiplier arg (=1, ) multiplier on examples per leaf (default\r\n",
      "                                       = log nodes)\r\n",
      "  --alpha arg (=0.1, )                 Alpha\r\n",
      "  --dream_repeats arg (=1, )           number of dream operations per example \r\n",
      "                                       (default = 1)\r\n",
      "  --top_K arg (=1, )                   top K prediction error (default 1)\r\n",
      "  --learn_at_leaf                      whether or not learn at leaf (default = \r\n",
      "                                       True)\r\n",
      "  --oas                                use oas at the leaf\r\n",
      "  --dream_at_update arg (=0, )         turn on dream operations at reward based\r\n",
      "                                       update as well\r\n",
      "  --online                             turn on dream operations at reward based\r\n",
      "                                       update as well\r\n",
      "Recall Tree:\r\n",
      "  --recall_tree arg       Use online tree for multiclass\r\n",
      "  --max_candidates arg    maximum number of labels per leaf in the tree\r\n",
      "  --bern_hyper arg (=1, ) recall tree depth penalty\r\n",
      "  --max_depth arg         maximum depth of the tree, default log_2 (#classes)\r\n",
      "  --node_only             only use node features, not full path features\r\n",
      "  --randomized_routing    randomized routing\r\n",
      "Logarithmic Time Multiclass Tree:\r\n",
      "  --log_multi arg              Use online tree for multiclass\r\n",
      "  --no_progress                disable progressive validation\r\n",
      "  --swap_resistance arg (=4, ) disable progressive validation\r\n",
      "  --swap_resistance arg (=4, ) higher = more resistance to swap, default=4\r\n",
      "Error Correcting Tournament Options:\r\n",
      "  --ect arg                Error correcting tournament with <k> labels\r\n",
      "  --error arg (=0, )       errors allowed by ECT\r\n",
      "  --link arg (=identity, ) Specify the link function: identity, logistic, glf1 \r\n",
      "                           or poisson\r\n",
      "Boosting:\r\n",
      "  --boosting arg        Online boosting with <N> weak learners\r\n",
      "  --gamma arg (=0.1, )  weak learner's edge (=0.1), used only by online BBM\r\n",
      "  --alg arg (=BBM, )    specify the boosting algorithm: BBM (default), logistic\r\n",
      "                        (AdaBoost.OL.W), adaptive (AdaBoost.OL)\r\n",
      "One Against All Options:\r\n",
      "  --oaa arg             One-against-all multiclass with <k> labels\r\n",
      "  --oaa_subsample arg   subsample this number of negative examples when \r\n",
      "                        learning\r\n",
      "  --probabilities       predict probabilites of all classes\r\n",
      "  --scores              output raw scores per class\r\n",
      "Top K:\r\n",
      "  --top arg             top k recommendation\r\n",
      "Experience Replay:\r\n",
      "  --replay_m arg              use experience replay at a specified level \r\n",
      "                              [b=classification/regression, m=multiclass, \r\n",
      "                              c=cost sensitive] with specified buffer size\r\n",
      "  --replay_m_count arg (=1, ) how many times (in expectation) should each \r\n",
      "                              example be played (default: 1 = permuting)\r\n",
      "Binary loss:\r\n",
      "  --binary              report loss as binary classification on -1,1\r\n",
      "Bootstrap:\r\n",
      "  --bootstrap arg       k-way bootstrap by online importance resampling\r\n",
      "  --bs_type arg         prediction type {mean,vote}\r\n",
      "scorer options:\r\n",
      "  --link arg (=identity, ) Specify the link function: identity, logistic, glf1 \r\n",
      "                           or poisson\r\n",
      "Stagewise polynomial options:\r\n",
      "  --stage_poly                use stagewise polynomial feature learning\r\n",
      "  --sched_exponent arg (=1, ) exponent controlling quantity of included \r\n",
      "                              features\r\n",
      "  --batch_sz arg (=1000, )    multiplier on batch size before including more \r\n",
      "                              features\r\n",
      "  --batch_sz_no_doubling      batch_sz does not double\r\n",
      "Low Rank Quadratics FA:\r\n",
      "  --lrqfa arg           use low rank quadratic features with field aware \r\n",
      "                        weights\r\n",
      "Low Rank Quadratics:\r\n",
      "  --lrq arg             use low rank quadratic features\r\n",
      "  --lrqdropout          use dropout training for low rank quadratic features\r\n",
      "Autolink:\r\n",
      "  --autolink arg        create link function with polynomial d\r\n",
      "VW options:\r\n",
      "  --marginal arg                   substitute marginal label estimates for ids\r\n",
      "  --initial_denominator arg (=1, ) initial denominator\r\n",
      "  --initial_numerator arg (=0.5, ) initial numerator\r\n",
      "  --compete                        enable competition with marginal features\r\n",
      "  --update_before_learn            update marginal values before learning\r\n",
      "  --unweighted_marginals           ignore importance weights when computing \r\n",
      "                                   marginals\r\n",
      "  --decay arg (=0, )               decay multiplier per event (1e-3 for \r",
      "\r\n",
      "                                   example)\r\n",
      "Matrix Factorization Reduction:\r\n",
      "  --new_mf arg          rank for reduction-based matrix factorization\r\n",
      "Neural Network:\r\n",
      "  --nn arg              Sigmoidal feedforward network with <k> hidden units\r\n",
      "  --inpass              Train or test sigmoidal feedforward network with input \r\n",
      "                        passthrough.\r\n",
      "  --multitask           Share hidden layer across all reduced tasks.\r\n",
      "  --dropout             Train or test sigmoidal feedforward network using \r\n",
      "                        dropout.\r\n",
      "  --meanfield           Train or test sigmoidal feedforward network using mean \r\n",
      "                        field.\r\n",
      "Confidence:\r\n",
      "  --confidence                 Get confidence for binary predictions\r\n",
      "  --confidence_after_training  Confidence after training\r\n",
      "Active Learning with Cover:\r\n",
      "  --active_cover                enable active learning with cover\r\n",
      "  --mellowness arg (=8, )       active learning mellowness parameter c_0. \r\n",
      "                                Default 8.\r\n",
      "  --alpha arg (=1, )            active learning variance upper bound parameter \r\n",
      "                                alpha. Default 1.\r\n",
      "  --beta_scale arg (=3.16228, ) active learning variance upper bound parameter \r\n",
      "                                beta_scale. Default std::sqrt(10).\r\n",
      "  --cover arg (=12, )           cover size. Default 12.\r\n",
      "  --oracular                    Use Oracular-CAL style query or not. Default \r\n",
      "                                false.\r\n",
      "Active Learning:\r\n",
      "  --active                enable active learning\r\n",
      "  --simulation            active learning simulation mode\r\n",
      "  --mellowness arg (=8, ) active learning mellowness parameter c_0. Default 8\r\n",
      "Experience Replay:\r\n",
      "  --replay_b arg              use experience replay at a specified level \r\n",
      "                              [b=classification/regression, m=multiclass, \r\n",
      "                              c=cost sensitive] with specified buffer size\r\n",
      "  --replay_b_count arg (=1, ) how many times (in expectation) should each \r\n",
      "                              example be played (default: 1 = permuting)\r\n",
      "Baseline options:\r\n",
      "  --baseline            Learn an additive baseline (from constant features) and\r\n",
      "                        a residual separately in regression.\r\n",
      "  --lr_multiplier arg   learning rate multiplier for baseline model\r\n",
      "  --global_only         use separate example with only global constant for \r\n",
      "                        baseline predictions\r\n",
      "  --check_enabled       only use baseline when the example contains enabled \r\n",
      "                        flag\r\n",
      "OjaNewton options:\r\n",
      "  --OjaNewton                    Online Newton with Oja's Sketch\r\n",
      "  --sketch_size arg (=10, )      size of sketch\r\n",
      "  --epoch_size arg (=1, )        size of epoch\r\n",
      "  --alpha arg (=1, )             mutiplicative constant for indentiy\r\n",
      "  --alpha_inverse arg            one over alpha, similar to learning rate\r\n",
      "  --learning_rate_cnt arg (=2, ) constant for the learning rate 1/t\r\n",
      "  --normalize arg                normalize the features or not\r\n",
      "  --random_init arg              randomize initialization of Oja or not\r\n",
      "LBFGS and Conjugate Gradient options:\r\n",
      "  --conjugate_gradient  use conjugate gradient based optimization\r\n",
      "LBFGS and Conjugate Gradient options:\r\n",
      "  --bfgs                       use conjugate gradient based optimization\r\n",
      "  --hessian_on                 use second derivative in line search\r\n",
      "  --mem arg (=15, )            memory in bfgs\r\n",
      "  --termination arg (=0.001, ) Termination threshold\r\n",
      "Latent Dirichlet Allocation:\r\n",
      "  --lda arg                    Run lda with <int> topics\r\n",
      "  --lda_alpha arg (=0.1, )     Prior on sparsity of per-document topic weights\r\n",
      "  --lda_rho arg (=0.1, )       Prior on sparsity of topic distributions\r\n",
      "  --lda_D arg (=10000, )       Number of documents\r\n",
      "  --lda_epsilon arg (=0.001, ) Loop convergence threshold\r\n",
      "  --minibatch arg (=1, )       Minibatch size, for LDA\r\n",
      "  --math-mode arg (=0, )       Math mode: simd, accuracy, fast-approx\r\n",
      "  --metrics                    Compute metrics\r\n",
      "Noop Learner:\r",
      "\r\n",
      "  --noop                do no learning\r\n",
      "Print psuedolearner:\r\n",
      "  --print               print examples\r\n",
      "Gradient Descent Matrix Factorization:\r\n",
      "  --rank arg            rank for matrix factorization.\r\n",
      "  --bfgs                Option not supported by this reduction\r\n",
      "  --conjugate_gradient  Option not supported by this reduction\r\n",
      "Network sending:\r\n",
      "  --sendto arg          send examples to <host>\r\n",
      "Stochastic Variance Reduced Gradient:\r\n",
      "  --svrg                  Streaming Stochastic Variance Reduced Gradient\r\n",
      "  --stage_size arg (=1, ) Number of passes per SVRG stage\r\n",
      "Follow the Regularized Leader:\r\n",
      "  --ftrl                FTRL: Follow the Proximal Regularized Leader\r\n",
      "  --coin                Coin betting optimizer\r\n",
      "  --pistol              PiSTOL: Parameter-free STOchastic Learning\r\n",
      "  --ftrl_alpha arg      Learning rate for FTRL optimization\r\n",
      "  --ftrl_beta arg       Learning rate for FTRL optimization\r\n",
      "Kernel SVM:\r\n",
      "  --ksvm                   kernel svm\r\n",
      "  --reprocess arg (=1, )   number of reprocess steps for LASVM\r\n",
      "  --pool_greedy            use greedy selection on mini pools\r\n",
      "  --para_active            do parallel active learning\r\n",
      "  --pool_size arg (=1, )   size of pools for active learning\r\n",
      "  --subsample arg (=1, )   number of items to subsample from the pool\r\n",
      "  --kernel arg (=linear, ) type of kernel (rbf or linear (default))\r\n",
      "  --bandwidth arg (=1, )   bandwidth of rbf kernel\r\n",
      "  --degree arg (=2, )      degree of poly kernel\r\n",
      "Gradient Descent options:\r\n",
      "  --sgd                  use regular stochastic gradient descent update.\r\n",
      "  --adaptive             use adaptive, individual learning rates.\r\n",
      "  --adax                 use adaptive learning rates with x^2 instead of g^2x^2\r\n",
      "  --invariant            use safe/importance aware updates.\r\n",
      "  --normalized           use per feature normalized updates\r\n",
      "  --sparse_l2 arg (=0, ) use per feature normalized updates\r\n",
      "  --l1_state arg (=0, )  use per feature normalized updates\r\n",
      "  --l2_state arg (=1, )  use per feature normalized updates\r\n",
      "Input options:\r\n",
      "  -d [ --data ] arg     Example set\r\n",
      "  --daemon              persistent daemon mode on port 26542\r\n",
      "  --foreground          in persistent daemon mode, do not run in the background\r\n",
      "  --port arg            port to listen on; use 0 to pick unused port\r\n",
      "  --num_children arg    number of children for persistent daemon mode\r\n",
      "  --pid_file arg        Write pid file in persistent daemon mode\r\n",
      "  --port_file arg       Write port used in persistent daemon mode\r\n",
      "  -c [ --cache ]        Use a cache.  The default is <data>.cache\r\n",
      "  --cache_file arg      The location(s) of cache_file.\r\n",
      "  --json                Enable JSON parsing.\r\n",
      "  --dsjson              Enable Decision Service JSON parsing.\r\n",
      "  -k [ --kill_cache ]   do not reuse existing cache: create a new one always\r\n",
      "  --compressed          use gzip format whenever possible. If a cache file is \r\n",
      "                        being created, this option creates a compressed cache \r\n",
      "                        file. A mixture of raw-text & compressed inputs are \r\n",
      "                        supported with autodetection.\r\n",
      "  --no_stdin            do not default to reading from stdin\r\n",
      "  --no_daemon           Force a loaded daemon or active learning model to \r\n",
      "                        accept local input instead of starting in daemon mode\r\n",
      "  --chain_hash          enable chain hash for feature name and string feature \r\n",
      "                        value. e.g. {'A': {'B': 'C'}} is hashed as A^B^C\r\n"
     ]
    }
   ],
   "source": [
    "!vw --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "62f9eb36-c321-43bb-823b-16e0dfa807fd",
    "_uuid": "e1af0fd07d8be18a75d911a2ca939b8af9839cf2"
   },
   "source": [
    "Vowpal Wabbit reads data from files or from standard input stream (stdin) with the following format:\n",
    "\n",
    "`[Label] [Importance] [Tag]|Namespace Features |Namespace Features ... |Namespace Features`\n",
    "\n",
    "`Namespace=String[:Value]`\n",
    "\n",
    "`Features=(String[:Value] )*`\n",
    "\n",
    "here [] denotes non-mandatory elements, and (...)\\* means multiple inputs allowed. \n",
    "\n",
    "- **Label** is a number. In the case of classification, it is usually 1 and -1; for regression, it is a real float value\n",
    "- **Importance** is a number. It denotes the sample weight during training. Setting this helps when working with imbalanced data.\n",
    "- **Tag** is a string without spaces. It is the \"name\" of the sample that VW saves upon prediction. In order to separate Tag from Importance, it is better to start Tag with the ' character.\n",
    "- **Namespace** is for creating different feature spaces. \n",
    "- **Features** are object features inside a given **Namespace**. Features have weight 1.0 by default, but it can be changed, for example feature:0.1. \n",
    "\n",
    "\n",
    "The following string matches the VW format:\n",
    "\n",
    "```\n",
    "1 1.0 |Subject WHAT car is this |Organization University of Maryland:0.5 College Park\n",
    "```\n",
    "\n",
    "\n",
    "Let's check the format by running VW with this training sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "5cbedd43-8d8e-4577-9a67-4f2879f0666c",
    "_uuid": "250fa571012a53fbe15f9b16bd88244dae4f805a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num weight bits = 18\r\n",
      "learning rate = 0.5\r\n",
      "initial_t = 0\r\n",
      "power_t = 0.5\r\n",
      "using no cache\r\n",
      "Reading datafile = \r\n",
      "num sources = 1\r\n",
      "average  since         example        example  current  current  current\r\n",
      "loss     last          counter         weight    label  predict features\r\n",
      "1.000000 1.000000            1            1.0   1.0000   0.0000       10\r\n",
      "\r\n",
      "finished run\r\n",
      "number of examples = 1\r\n",
      "weighted example sum = 1.000000\r\n",
      "weighted label sum = 1.000000\r\n",
      "average loss = 1.000000\r\n",
      "best constant = 1.000000\r\n",
      "best constant's loss = 0.000000\r\n",
      "total feature number = 10\r\n"
     ]
    }
   ],
   "source": [
    "! echo '1 1.0 |Subject WHAT car is this |Organization University of Maryland:0.5 College Park' | vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "250ad844-c8bc-4cc6-a1dd-cf4770d7c840",
    "_uuid": "1d754e1b0d24913b137f42b84ccdf9d46ce53f05"
   },
   "source": [
    "VW is a wonderful tool for working with text data. We'll illustrate it with the [20newsgroups dataset](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html), which contains letters from 20 different newsletters.\n",
    "\n",
    "\n",
    "### 3.1. News. Binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "a37611a4-5bdb-40bb-9b89-bfddd8726ba9",
    "_uuid": "0f527d54e1a759be5fb53665ae4b768116094b27"
   },
   "outputs": [],
   "source": [
    "# load data with sklearn's function\n",
    "newsgroups = fetch_20newsgroups(data_home=PATH_TO_WRITE_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "7fad47bd-c5fc-4b56-b024-0e866137d07b",
    "_uuid": "a582c83f4d792d71d12e5063d7539c040b017a67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups[\"target_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9eab187f-162a-4a1c-bcaa-6e96bbaeb807",
    "_uuid": "307c3d13c7525e41cba581816a9ef75660d54fb2"
   },
   "source": [
    "Lets look at the first document in this collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "d571d3d0-fba9-4d2f-a4a9-3a36e80fe456",
    "_uuid": "039c32b72a84277884c788de8fe2a5e692a4dfb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "rec.autos\n",
      "-----\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "text = newsgroups[\"data\"][0]\n",
    "target = newsgroups[\"target_names\"][newsgroups[\"target\"][0]]\n",
    "\n",
    "print(\"-----\")\n",
    "print(target)\n",
    "print(\"-----\")\n",
    "print(text.strip())\n",
    "print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bb940e9e-e2bf-4f39-b8a2-467100548f40",
    "_uuid": "a464de9c01ff461f95ef1cba04acbe0211723c58"
   },
   "source": [
    "Now we convert the data into something Vowpal Wabbit can understand. We will throw away words shorter than 3 symbols. Here, we will skip some important NLP stages such as stemming and lemmatization; however, we will later see that VW solves the problem even without these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "61c25a92-1b0a-45cf-904f-6c35de89575f",
    "_uuid": "9b480cff8801ad51f371b05f6f63225c758883ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 |text from lerxst wam umd edu where thing subject what car this nntp posting host rac3 wam umd edu organization university maryland college park lines was wondering anyone out there could enlighten this car saw the other day was door sports car looked from the late 60s early 70s was called bricklin the doors were really small addition the front bumper was separate from the rest the body this all know anyone can tellme model name engine specs years production where this car made history whatever info you have this funky looking car please mail thanks brought you your neighborhood lerxst\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_vw_format(document, label=None):\n",
    "    return (\n",
    "        str(label or \"\")\n",
    "        + \" |text \"\n",
    "        + \" \".join(re.findall(\"\\w{3,}\", document.lower()))\n",
    "        + \"\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "to_vw_format(text, 1 if target == \"rec.autos\" else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a9ff9575-96b8-421c-9ebb-fe5de97b4d79",
    "_uuid": "0fada3ac4275dc108ea54a0be7efa8ab176ca06f"
   },
   "source": [
    "We split the dataset into train and test and write these into separate files. We will consider a document as positive if it corresponds to **rec.autos**. Thus, we are constructing a model which distinguishes articles about cars from other topics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "297c4ed7-3157-412e-b3af-1bc59084defd",
    "_uuid": "f5754e324f2165a47ab603e2e5fafa5b681ea1e9"
   },
   "outputs": [],
   "source": [
    "all_documents = newsgroups[\"data\"]\n",
    "all_targets = [\n",
    "    1 if newsgroups[\"target_names\"][target] == \"rec.autos\" else -1\n",
    "    for target in newsgroups[\"target\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "d0cd644c-fdd2-4b46-9ff5-377ef12a3d6e",
    "_uuid": "623b5b239dda745dc0e79a7b225825eed8f98d09"
   },
   "outputs": [],
   "source": [
    "train_documents, test_documents, train_labels, test_labels = train_test_split(\n",
    "    all_documents, all_targets, random_state=7\n",
    ")\n",
    "\n",
    "with open(os.path.join(PATH_TO_WRITE_DATA, \"20news_train.vw\"), \"w\") as vw_train_data:\n",
    "    for text, target in zip(train_documents, train_labels):\n",
    "        vw_train_data.write(to_vw_format(text, target))\n",
    "with open(os.path.join(PATH_TO_WRITE_DATA, \"20news_test.vw\"), \"w\") as vw_test_data:\n",
    "    for text in test_documents:\n",
    "        vw_test_data.write(to_vw_format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "601ec250-c847-4c9e-8d47-ca00b8b659af",
    "_uuid": "6330fc49440e8801cbfee9aa075df523e845ae23"
   },
   "source": [
    "Now, we pass the created training file to Vowpal Wabbit. We solve the classification problem with a hinge loss function (linear SVM). The trained model will be saved in the `20news_model.vw` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "80f2960a-2389-4810-9b04-1928b613b4b2",
    "_uuid": "7a5a15cc11e801a98b493bab026136c9eeb33816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = ../../tmp//20news_model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../tmp//20news_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0  -1.0000   0.0000      157\n",
      "0.911276 0.822551            2            2.0  -1.0000  -0.1774      159\n",
      "0.605793 0.300311            4            4.0  -1.0000  -0.3994       92\n",
      "0.419594 0.233394            8            8.0  -1.0000  -0.8167      129\n",
      "0.313998 0.208402           16           16.0  -1.0000  -0.6509      108\n",
      "0.196014 0.078029           32           32.0  -1.0000  -1.0000      115\n",
      "0.183158 0.170302           64           64.0  -1.0000  -0.7072      114\n",
      "0.261046 0.338935          128          128.0   1.0000  -0.7900      110\n",
      "0.262910 0.264774          256          256.0  -1.0000  -0.6425       44\n",
      "0.216663 0.170415          512          512.0  -1.0000  -1.0000      160\n",
      "0.176710 0.136757         1024         1024.0  -1.0000  -1.0000      194\n",
      "0.134541 0.092371         2048         2048.0  -1.0000  -1.0000      438\n",
      "0.104403 0.074266         4096         4096.0  -1.0000  -1.0000      644\n",
      "0.081329 0.058255         8192         8192.0  -1.0000  -1.0000      174\n",
      "\n",
      "finished run\n",
      "number of examples = 8485\n",
      "weighted example sum = 8485.000000\n",
      "weighted label sum = -7555.000000\n",
      "average loss = 0.079837\n",
      "best constant = -1.000000\n",
      "best constant's loss = 0.109605\n",
      "total feature number = 2048932\n"
     ]
    }
   ],
   "source": [
    "!vw -d $PATH_TO_WRITE_DATA/20news_train.vw \\\n",
    " --loss_function hinge -f $PATH_TO_WRITE_DATA/20news_model.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8d4e9c7a-c55b-4e18-a26a-d9b63db8ad47",
    "_uuid": "efc30d9b5fa31f0e39eb486e85f6775ac52cb229"
   },
   "source": [
    "VW prints a lot of interesting info while training (one can suppress it with the `--quiet` parameter). You can see documentation of the diagnostic output on [GitHub](https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial#vws-diagnostic-information). Note how average loss drops while training. For loss computation, VW uses samples it has never seen before, so this measure is usually accurate. Now, we apply our trained model to the test set, saving predictions into a file with the `-p` flag:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "17c99751-4e30-4251-b18f-fe6ed8a34e58",
    "_uuid": "276f1431b121543e67f668bb5e9d601dd882e98e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\r\n",
      "predictions = ../../tmp//20news_test_predictions.txt\r\n",
      "Num weight bits = 18\r\n",
      "learning rate = 0.5\r\n",
      "initial_t = 0\r\n",
      "power_t = 0.5\r\n",
      "using no cache\r\n",
      "Reading datafile = ../../tmp//20news_test.vw\r\n",
      "num sources = 1\r\n",
      "average  since         example        example  current  current  current\r\n",
      "loss     last          counter         weight    label  predict features\r\n",
      "    n.a.     n.a.            1            1.0  unknown   1.0000      349\r\n",
      "    n.a.     n.a.            2            2.0  unknown  -1.0000       50\r\n",
      "    n.a.     n.a.            4            4.0  unknown  -1.0000      251\r\n",
      "    n.a.     n.a.            8            8.0  unknown  -1.0000      237\r\n",
      "    n.a.     n.a.           16           16.0  unknown  -0.8978      106\r\n",
      "    n.a.     n.a.           32           32.0  unknown  -1.0000      964\r\n",
      "    n.a.     n.a.           64           64.0  unknown  -1.0000      261\r\n",
      "    n.a.     n.a.          128          128.0  unknown   0.4621       82\r\n",
      "    n.a.     n.a.          256          256.0  unknown  -1.0000      186\r\n",
      "    n.a.     n.a.          512          512.0  unknown  -1.0000      162\r\n",
      "    n.a.     n.a.         1024         1024.0  unknown  -1.0000      283\r\n",
      "    n.a.     n.a.         2048         2048.0  unknown  -1.0000      104\r\n",
      "\r\n",
      "finished run\r\n",
      "number of examples = 2829\r\n",
      "weighted example sum = 2829.000000\r\n",
      "weighted label sum = 0.000000\r\n",
      "average loss = n.a.\r\n",
      "total feature number = 642215\r\n"
     ]
    }
   ],
   "source": [
    "!vw -i $PATH_TO_WRITE_DATA/20news_model.vw -t -d $PATH_TO_WRITE_DATA/20news_test.vw \\\n",
    "-p $PATH_TO_WRITE_DATA/20news_test_predictions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b3c2b322-058b-4051-a29e-961e9691947f",
    "_uuid": "e478d52c8fd3c52b8a46d6e1dd5ebccfd691748e"
   },
   "source": [
    "Now we load our predictions, compute AUC, and plot the ROC curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "93d9f296-f06b-4d18-94a5-e18ccf88b094",
    "_uuid": "40b4112f1afa764db10b58b0ab05adfed48ab388"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(PATH_TO_WRITE_DATA, \"20news_test_predictions.txt\")) as pred_file:\n",
    "    test_prediction = [float(label) for label in pred_file.readlines()]\n",
    "\n",
    "auc = roc_auc_score(test_labels, test_prediction)\n",
    "roc_curve = roc_curve(test_labels, test_prediction)\n",
    "\n",
    "with plt.xkcd():\n",
    "    plt.plot(roc_curve[0], roc_curve[1])\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(\"test AUC = %f\" % (auc))\n",
    "    plt.axis([-0.05, 1.05, -0.05, 1.05]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a302f698-1f6f-4653-a1a1-ef467919ca1e",
    "_uuid": "5aa3b9722f255cb9db25c8fe5991c1e2c7a17f71"
   },
   "source": [
    "The AUC value we get shows that we have achieved high classification quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6cc41756-d83c-48a5-93f6-56c238487b51",
    "_uuid": "47ea9632a74d49a003c1d876661af0113efd6bd4"
   },
   "source": [
    "### 3.2. News. Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ad900d77-3eb6-413b-ba95-7d33d036e655",
    "_uuid": "2fd54a3102db4cf3d3665877acffb3cead417a2f"
   },
   "source": [
    "We will use the same news dataset, but, this time, we will solve a multiclass classification problem. `Vowpal Wabbit` is a little picky – it wants labels starting from 1 till K, where K – is the number of classes in the classification task (20 in our case). So we will use LabelEncoder and add 1 afterwards (recall that `LabelEncoder` maps labels into range from 0 to K-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "e94dfe85-61d6-42d2-b19e-89923b511535",
    "_uuid": "30fca7585b9d841b5925ec9b3db9b12ff1bb5142"
   },
   "outputs": [],
   "source": [
    "all_documents = newsgroups[\"data\"]\n",
    "topic_encoder = LabelEncoder()\n",
    "all_targets_mult = topic_encoder.fit_transform(newsgroups[\"target\"]) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0d4b5845-3bc5-4c2d-ba00-5977b5f108cc",
    "_uuid": "93289fedab1875334df6632138311299dfe7dc4d"
   },
   "source": [
    "**The data is the same, but we have changed the labels, train_labels_mult and test_labels_mult, into label vectors from 1 to 20.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "90e22502-efe9-4a2c-9868-fa6a18ed91b2",
    "_uuid": "f90ea2c247690e680d26f6d30992daf45ffd0315"
   },
   "outputs": [],
   "source": [
    "train_documents, test_documents, train_labels_mult, test_labels_mult = train_test_split(\n",
    "    all_documents, all_targets_mult, random_state=7\n",
    ")\n",
    "\n",
    "with open(os.path.join(PATH_TO_WRITE_DATA, \"20news_train_mult.vw\"), \"w\") as vw_train_data:\n",
    "    for text, target in zip(train_documents, train_labels_mult):\n",
    "        vw_train_data.write(to_vw_format(text, target))\n",
    "with open(os.path.join(PATH_TO_WRITE_DATA, \"20news_test_mult.vw\"), \"w\") as vw_test_data:\n",
    "    for text in test_documents:\n",
    "        vw_test_data.write(to_vw_format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "478ead84-c063-4383-baac-7deaa627d83f",
    "_uuid": "c0f488bb8182487c1393e5b9f0fdbc301de58a02"
   },
   "source": [
    "We train Vowpal Wabbit in multiclass classification mode, passing the `oaa` parameter(\"one against all\") with the number of classes. Also, let's see what parameters our model quality is dependent on (more info can be found in the [official Vowpal Wabbit tutorial](https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial)):\n",
    " - learning rate (-l, 0.5 default) – rate of weight change on every step\n",
    " - learning rate decay (--power_t, 0.5 default) – it is proven in practice, that, if the learning rate drops with the number of steps in stochastic gradient descent, we approach the minimum loss better\n",
    " - loss function (--loss_function) – the entire training algorithm depends on it. See [docs](https://github.com/JohnLangford/vowpal_wabbit/wiki/Loss-functions) for loss functions\n",
    " - Regularization (-l1) – note that VW  calculates regularization for every object. That is why we usually set regularization values to about $10^{-20}.$\n",
    " \n",
    "Additionally, we can try automatic Vowpal Wabbit parameter tuning with [Hyperopt](https://github.com/hyperopt/hyperopt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "80ae364e-8332-41db-bdc3-7f642bb24d7a",
    "_uuid": "97ea9ebcb6ed46b5512f5a9364680e501c2925cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = ../../tmp//20news_model_mult.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../tmp//20news_train_mult.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0       15        1      157\n",
      "1.000000 1.000000            2            2.0        2       15      159\n",
      "1.000000 1.000000            4            4.0       15       10       92\n",
      "1.000000 1.000000            8            8.0       16       15      129\n",
      "1.000000 1.000000           16           16.0       13       12      108\n",
      "0.937500 0.875000           32           32.0        2        9      115\n",
      "0.906250 0.875000           64           64.0       16       16      114\n",
      "0.867188 0.828125          128          128.0        8        4      110\n",
      "0.816406 0.765625          256          256.0        7       15       44\n",
      "0.646484 0.476562          512          512.0       13        9      160\n",
      "0.502930 0.359375         1024         1024.0        3        4      194\n",
      "0.388672 0.274414         2048         2048.0        1        1      438\n",
      "0.300293 0.211914         4096         4096.0       11       11      644\n",
      "0.225098 0.149902         8192         8192.0        5        5      174\n",
      "\n",
      "finished run\n",
      "number of examples = 8485\n",
      "weighted example sum = 8485.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.222392\n",
      "total feature number = 2048932\n",
      "CPU times: user 6.77 ms, sys: 10.4 ms, total: 17.2 ms\n",
      "Wall time: 756 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw --oaa 20 $PATH_TO_WRITE_DATA/20news_train_mult.vw -f $PATH_TO_WRITE_DATA/20news_model_mult.vw \\\n",
    "--loss_function=hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "4d78df8b-f6d2-477a-b5be-a5f7364c0e56",
    "_uuid": "d30d194b2be9521d609d703385f528c24a557aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = ../../tmp//20news_test_predictions_mult.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../tmp//20news_test_mult.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "    n.a.     n.a.            1            1.0  unknown        8      349\n",
      "    n.a.     n.a.            2            2.0  unknown        6       50\n",
      "    n.a.     n.a.            4            4.0  unknown       18      251\n",
      "    n.a.     n.a.            8            8.0  unknown       18      237\n",
      "    n.a.     n.a.           16           16.0  unknown        4      106\n",
      "    n.a.     n.a.           32           32.0  unknown       15      964\n",
      "    n.a.     n.a.           64           64.0  unknown        4      261\n",
      "    n.a.     n.a.          128          128.0  unknown        8       82\n",
      "    n.a.     n.a.          256          256.0  unknown       10      186\n",
      "    n.a.     n.a.          512          512.0  unknown        1      162\n",
      "    n.a.     n.a.         1024         1024.0  unknown       11      283\n",
      "    n.a.     n.a.         2048         2048.0  unknown       14      104\n",
      "\n",
      "finished run\n",
      "number of examples = 2829\n",
      "weighted example sum = 2829.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = n.a.\n",
      "total feature number = 642215\n",
      "CPU times: user 3.97 ms, sys: 7.58 ms, total: 11.6 ms\n",
      "Wall time: 470 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -i $PATH_TO_WRITE_DATA/20news_model_mult.vw -t -d $PATH_TO_WRITE_DATA/20news_test_mult.vw \\\n",
    "-p $PATH_TO_WRITE_DATA/20news_test_predictions_mult.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "bf4c66cf-3039-4ac4-a129-e52652c16d8d",
    "_uuid": "f6911717662ade8c466cc2f3681f356619d8676c"
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(PATH_TO_WRITE_DATA, \"20news_test_predictions_mult.txt\")\n",
    ") as pred_file:\n",
    "    test_prediction_mult = [float(label) for label in pred_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "c8cd9521-6c23-412b-959d-19e9f95bd5ee",
    "_uuid": "c110cfb692d0c280009ca815efa504f5889e28a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8734535171438671"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels_mult, test_prediction_mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "365da3c4-6bcb-40fa-8786-d57415595491",
    "_uuid": "ab8ac32cc2357207807e8c262177e0347e9f6d71"
   },
   "source": [
    "Here is how often the model misclassifies atheism with other topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "5b40bd39-4895-4713-be3a-2fea6fa37062",
    "_uuid": "fefe7d01f98e8cd3af7ce5a3b7d0f859755e5047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos 1\n",
      "rec.sport.baseball 1\n",
      "sci.med 1\n",
      "soc.religion.christian 3\n",
      "talk.religion.misc 5\n"
     ]
    }
   ],
   "source": [
    "M = confusion_matrix(test_labels_mult, test_prediction_mult)\n",
    "for i in np.where(M[0, :] > 0)[0][1:]:\n",
    "    print(newsgroups[\"target_names\"][i], M[0, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cab1c6f7-515d-4bf3-9054-5bc25d81be8e",
    "_uuid": "dc891b0f4124cdc76a2f9db9340d49055a91e1f8"
   },
   "source": [
    "### 3.3. IMDB movie reviews\n",
    "In this part we will do binary classification of [IMDB](http://www.imdb.com) (International Movie DataBase) movie reviews. We will see how fast Vowpal Wabbit performs.\n",
    "\n",
    "Using the `load_files` function from `sklearn.datasets`, we load the movie reviews datasets. It's the same dataset we used in topic04 part4 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "a1827aa1-5bc7-4838-bb01-68792de451b6",
    "_uuid": "e719b5b6c976cf9daf10a9f3b7c35b4cde79b057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the dataset from:   http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "# Download the dataset if not already in place\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "\n",
    "def load_imdb_dataset(extract_path=PATH_TO_WRITE_DATA, overwrite=False):\n",
    "    # check if existed already\n",
    "    if (\n",
    "        os.path.isfile(os.path.join(extract_path, \"aclImdb\", \"README\"))\n",
    "        and not overwrite\n",
    "    ):\n",
    "        print(\"IMDB dataset is already in place.\")\n",
    "        return\n",
    "\n",
    "    print(\"Downloading the dataset from:  \", url)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    tar = tarfile.open(mode=\"r:gz\", fileobj=BytesIO(response.content))\n",
    "\n",
    "    data = tar.extractall(extract_path)\n",
    "\n",
    "\n",
    "load_imdb_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read train data, separate labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMDB = PATH_TO_WRITE_DATA + \"aclImdb\"\n",
    "\n",
    "reviews_train = load_files(\n",
    "    os.path.join(PATH_TO_IMDB, \"train\"), categories=[\"pos\", \"neg\"]\n",
    ")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_cell_guid": "db550541-630a-47a5-8b98-246d94a3fb33",
    "_uuid": "593032d9be6e7aff583e0c7ba40e3e801b136edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in training data: 25000\n",
      "[12500 12500]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents in training data: %d\" % len(text_train))\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "50ea99f8-6680-4a77-b3fb-a9fb18fd11b3",
    "_uuid": "6cd9d12d23bec99ee3df859934378ed1a911be22"
   },
   "source": [
    "Do the same for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "ce60fd02-e5d4-40aa-a5db-33556ef7063f",
    "_uuid": "8fea469dd838a26671f234d54cf82d6f57188e73"
   },
   "outputs": [],
   "source": [
    "reviews_test = load_files(os.path.join(PATH_TO_IMDB, \"test\"), categories=[\"pos\", \"neg\"])\n",
    "text_test, y_test = reviews_test.data, reviews_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in test data: 25000\n",
      "[12500 12500]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents in test data: %d\" % len(text_test))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a7f87c80-8d74-47f1-9d47-cd31542da37d",
    "_uuid": "d37600cecaa2fd716479ed286ca9985380722c40"
   },
   "source": [
    "Take a look at examples of reviews and their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_cell_guid": "213017e1-25f0-4d08-8d9c-5341b449b8f6",
    "_uuid": "aea5acfcef80c4006dbcab233d237d2cd091ab48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_cell_guid": "23c8ca4d-7287-406a-8381-f9c9c095f1b7",
    "_uuid": "976c29d60e5fc1da27e36b5c34dd1fa4185cd083"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]  # good review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "b4cd5590-5952-4388-9960-37702e78be4f",
    "_uuid": "2fe24a84eb18599fb67664a63e3b2178ee29ee26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Words can\\'t describe how bad this movie is. I can\\'t explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clich\\xc3\\xa9s, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won\\'t list them here, but just mention the coloring of the plane. They didn\\'t even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys\\' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you\\'re choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_cell_guid": "0faa88f7-c96d-4073-9b16-b6d68d31d354",
    "_uuid": "f64122c2e93648b75494df26b1de4bf01358df35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]  # bad review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "23032bfe-25d1-4f79-b24e-a4cb69f44127",
    "_uuid": "0ce9e75db41712f6f9161f9d6cd8000381a5b3ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 |text words can describe how bad this movie can explain writing only you have too see for yourself get grip how horrible movie really can not that recommend you that there are many clich xc3 xa9s mistakes and all other negative things you can imagine here that will just make you cry start with the technical first there are lot mistakes regarding the airplane won list them here but just mention the coloring the plane they didn even manage show airliner the colors fictional airline but instead used 747 painted the original boeing livery very bad the plot stupid and has been done many times before only much much better there are many ridiculous moments here that lost count really early also was the bad guys side all the time the movie because the good guys were stupid executive decision should without doubt you choice over this one even the turbulence movies are better fact every other movie the world better than this one\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_vw_format(str(text_train[1]), 1 if y_train[0] == 1 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "886409fe-bdbf-4e09-9091-1912143715b9",
    "_uuid": "844598ae3aa0064ecfb4cb778df0c555a6b91403"
   },
   "source": [
    "Now, we prepare training (`movie_reviews_train.vw`), validation (`movie_reviews_valid.vw`), and test (`movie_reviews_test.vw`) sets for Vowpal Wabbit. We will use 70% for training, 30% for the hold-out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_cell_guid": "c08edd2b-7290-4e70-9072-895e33923d44",
    "_uuid": "7309769413ef059831390aea012334a5d7482817"
   },
   "outputs": [],
   "source": [
    "train_share = int(0.7 * len(text_train))\n",
    "train, valid = text_train[:train_share], text_train[train_share:]\n",
    "train_labels, valid_labels = y_train[:train_share], y_train[train_share:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_cell_guid": "a30cddd4-fceb-46ca-87a8-1b7b7d3b36d1",
    "_uuid": "9154377a268f463e98c17432a84a77d03e68052e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 7500)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels), len(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_cell_guid": "6d25382f-b135-47f8-a82c-2568ad02f9ff",
    "_uuid": "cce438177377598771a890dc94651de5a6a8495e"
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(PATH_TO_WRITE_DATA, \"movie_reviews_train.vw\"), \"w\"\n",
    ") as vw_train_data:\n",
    "    for text, target in zip(train, train_labels):\n",
    "        vw_train_data.write(to_vw_format(str(text), 1 if target == 1 else -1))\n",
    "with open(\n",
    "    os.path.join(PATH_TO_WRITE_DATA, \"movie_reviews_valid.vw\"), \"w\"\n",
    ") as vw_train_data:\n",
    "    for text, target in zip(valid, valid_labels):\n",
    "        vw_train_data.write(to_vw_format(str(text), 1 if target == 1 else -1))\n",
    "with open(os.path.join(PATH_TO_WRITE_DATA, \"movie_reviews_test.vw\"), \"w\") as vw_test_data:\n",
    "    for text in text_test:\n",
    "        vw_test_data.write(to_vw_format(str(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_cell_guid": "cb999742-8ad7-428d-8f66-f015d38de4f8",
    "_uuid": "8d87247a0d044e81b545e37ffaa59a96712a252f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 |text zero day leads you think even think why two boys young men would what they did commit mutual suicide via slaughtering their classmates captures what must beyond bizarre mode being for two humans who have decided withdraw from common civility order define their own mutual world via coupled destruction not perfect movie but given what money time the filmmaker and actors had remarkable product terms explaining the motives and actions the two young suicide murderers better than elephant terms being film that gets under our rationalistic skin far far better film than almost anything you are likely see flawed but honest with terrible honesty\r\n",
      "-1 |text words can describe how bad this movie can explain writing only you have too see for yourself get grip how horrible movie really can not that recommend you that there are many clich xc3 xa9s mistakes and all other negative things you can imagine here that will just make you cry start with the technical first there are lot mistakes regarding the airplane won list them here but just mention the coloring the plane they didn even manage show airliner the colors fictional airline but instead used 747 painted the original boeing livery very bad the plot stupid and has been done many times before only much much better there are many ridiculous moments here that lost count really early also was the bad guys side all the time the movie because the good guys were stupid executive decision should without doubt you choice over this one even the turbulence movies are better fact every other movie the world better than this one\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 $PATH_TO_WRITE_DATA/movie_reviews_train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_cell_guid": "f25cd0d3-1767-41f1-b7bf-096224619bc5",
    "_uuid": "b63440f7ffebc472ecbe54d8e3aef8c3a3b75fa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 |text matter life and death what can you really say that would properly justice the genius and beauty this film powell and pressburger visual imagination knows bounds every frame filled with fantastically bold compositions the switches between the bold colours the real world the stark black and white heaven ingenious showing visually just how much more vibrant life the final court scene also fantastic the judge and jury descend the stairway heaven hold court over peter david niven operation all the performances are spot roger livesey being standout and the romantic energy the film beautiful never has there been more romantic film than this there has haven seen matter life and death all about the power love and just how important life and jack cardiff cinematography reason enough watch the film alone the way lights kim hunter face makes her all the more beautiful what genius can make simple things such game table tennis look exciting and the sound design also impeccable the way the sound mutes vital points was decision way ahead its time this true classic that can restore anyone faith cinema under appreciated its initial release and today audiences but one all time favourites which why give this film word beautiful\r\n",
      "1 |text while this was better movie than 101 dalmations live action not animated version think still fell little short what disney could was well filmed the music was more suited the action and the effects were better done compared 101 the acting was perhaps better but then the human characters were given far more appropriate roles this sequel and glenn close really not missed the first movie she makes shine her poor lackey and the overzealous furrier sidekicks are wonderful characters play off and they add the spectacle disney has given this great family film with little objectionable material and yet remains fun and interesting for adults and children alike bound classic many disney films are here hoping the third will even better still because you know they probably want make one\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 $PATH_TO_WRITE_DATA/movie_reviews_valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_cell_guid": "eaa1a658-e6e0-42f1-9c30-14be762fc7d9",
    "_uuid": "fd4e364bad19a64110f7ec839a56a2776222306c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |text don hate heather graham because she beautiful hate her because she fun watch this movie like the hip clothing and funky surroundings the actors this flick work well together casey affleck hysterical and heather graham literally lights the screen the minor characters goran visnjic sigh and patricia velazquez are talented they are gorgeous congratulations miramax director lisa krueger\r\n",
      " |text don know how this movie has received many positive comments one can call artistic and beautifully filmed but those things don make for the empty plot that was filled with sexual innuendos wish had not wasted time watch this movie rather than being biographical was poor excuse for promoting strange and lewd behavior was just another hollywood attempt convince that that kind life normal and from the very beginning asked self what was the point this movie and continued watching hoping that would change and was quite disappointed that continued the same vein glad did not spend the money see this theater\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 $PATH_TO_WRITE_DATA/movie_reviews_test.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0cedab5e-5896-4439-beeb-96b268382587",
    "_uuid": "6403759f3d06322ee2b8e4017f181bc9681661ea"
   },
   "source": [
    "**Now we launch Vowpal Wabbit with the following arguments:**\n",
    "\n",
    " - `-d`, path to training set (corresponding .vw file)\n",
    " - `--loss_function` – hinge (feel free to experiment here)\n",
    " - `-f` – path to the output file (which can also be in the .vw format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_cell_guid": "89094f9e-7453-4137-87b0-21df78627ae6",
    "_uuid": "4e27dea292bfde2224e802d60c00aad0fbac3274"
   },
   "outputs": [],
   "source": [
    "!vw -d $PATH_TO_WRITE_DATA/movie_reviews_train.vw --loss_function hinge \\\n",
    "-f $PATH_TO_WRITE_DATA/movie_reviews_model.vw --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7653ab5e-de84-47c0-9981-80fbd6a04783",
    "_uuid": "66ccbe8a95fea95703c28f21af5f6b9a3dcd87f6"
   },
   "source": [
    "Next, make the hold-out prediction with the following VW arguments:\n",
    " - `-i` –path to the trained model (.vw file)\n",
    " - `-d` – path to the hold-out set (.vw file) \n",
    " - `-p` – path to a txt-file where the predictions will be stored\n",
    " - `-t` - tells VW to ignore labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_cell_guid": "7fbac967-4a81-4eff-9d31-721a197ed568",
    "_uuid": "c8ae7e58aeacc3e88910b62aff684ab12fb970e1"
   },
   "outputs": [],
   "source": [
    "!vw -i $PATH_TO_WRITE_DATA/movie_reviews_model.vw -t \\\n",
    "-d $PATH_TO_WRITE_DATA/movie_reviews_valid.vw -p $PATH_TO_WRITE_DATA/movie_valid_pred.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5fa99f83-de1f-42d7-97ba-52da84c086f8",
    "_uuid": "9664438878f6d1c633bc67ee13266b929bab7dd0"
   },
   "source": [
    "Read the predictions from the text file and estimate the accuracy and ROC AUC. Note that VW prints probability estimates of the +1 class. These estimates are distributed from  -1 to 1, so we can convert these into binary answers, assuming that positive values belong to class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_cell_guid": "609497c1-de20-436d-9910-018316f36e8e",
    "_uuid": "8cce125db3a615ff84b0892819f1b5f7c680a3e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.885\n",
      "AUC: 0.942\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(PATH_TO_WRITE_DATA, \"movie_valid_pred.txt\")) as pred_file:\n",
    "    valid_prediction = [float(label) for label in pred_file.readlines()]\n",
    "print(\n",
    "    \"Accuracy: {}\".format(\n",
    "        round(\n",
    "            accuracy_score(\n",
    "                valid_labels, [int(pred_prob > 0) for pred_prob in valid_prediction]\n",
    "            ),\n",
    "            3,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(valid_labels, valid_prediction), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "699aac8c-8b17-4df1-9258-45f997ae0f79",
    "_uuid": "d19e8357504987994c53d41ea373891aab41afa6"
   },
   "source": [
    "Again, do the same for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_cell_guid": "aaa8c5c7-aa05-4cdd-a06e-bf7325972691",
    "_uuid": "36f5d2d1336d537c95947e884207ecffe18e2d91"
   },
   "outputs": [],
   "source": [
    "!vw -i $PATH_TO_WRITE_DATA/movie_reviews_model.vw -t \\\n",
    "-d $PATH_TO_WRITE_DATA/movie_reviews_test.vw \\\n",
    "-p $PATH_TO_WRITE_DATA/movie_test_pred.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_cell_guid": "7a61e739-89f4-44d1-a290-9ad2be4bdffd",
    "_uuid": "b3cf5f3efa4dbaf05baff4f4900c61665f2d9fee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n",
      "AUC: 0.94\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(PATH_TO_WRITE_DATA, \"movie_test_pred.txt\")) as pred_file:\n",
    "    test_prediction = [float(label) for label in pred_file.readlines()]\n",
    "print(\n",
    "    \"Accuracy: {}\".format(\n",
    "        round(\n",
    "            accuracy_score(\n",
    "                y_test, [int(pred_prob > 0) for pred_prob in test_prediction]\n",
    "            ),\n",
    "            3,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(y_test, test_prediction), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b5ecbd7f-1bf9-496a-a35f-f82a1ea2db10",
    "_uuid": "45c4a3badafdf39fc53a6bbc32d2c43b15b88c98"
   },
   "source": [
    "Let's try to achieve a higher accuracy by incorporating bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_cell_guid": "c5b25dce-c730-4031-8938-1b9fa64575b6",
    "_uuid": "98fbb3a6f858b362aef8f797469075eec9072aaf"
   },
   "outputs": [],
   "source": [
    "!vw -d $PATH_TO_WRITE_DATA/movie_reviews_train.vw \\\n",
    "--loss_function hinge --ngram 2 -f $PATH_TO_WRITE_DATA/movie_reviews_model2.vw --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_cell_guid": "17ceb519-ab1f-4184-b9c2-9eb925b32ea8",
    "_uuid": "48aa4c0a6c58be2781ed607a2393de37083345ae"
   },
   "outputs": [],
   "source": [
    "!vw -i$PATH_TO_WRITE_DATA/movie_reviews_model2.vw -t -d $PATH_TO_WRITE_DATA/movie_reviews_valid.vw \\\n",
    "-p $PATH_TO_WRITE_DATA/movie_valid_pred2.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_cell_guid": "d1c01554-e2b6-4a55-97b9-0d17c8b26686",
    "_uuid": "be78a33c70c03e1bc9a48a25e804248930fba2c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.894\n",
      "AUC: 0.954\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(PATH_TO_WRITE_DATA, \"movie_valid_pred2.txt\")) as pred_file:\n",
    "    valid_prediction = [float(label) for label in pred_file.readlines()]\n",
    "print(\n",
    "    \"Accuracy: {}\".format(\n",
    "        round(\n",
    "            accuracy_score(\n",
    "                valid_labels, [int(pred_prob > 0) for pred_prob in valid_prediction]\n",
    "            ),\n",
    "            3,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(valid_labels, valid_prediction), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_cell_guid": "3015a9e6-f814-4beb-9d37-f8c6a2e2c546",
    "_uuid": "f1aa2121a7ee92577ad4058b0688f8290d24e1d5"
   },
   "outputs": [],
   "source": [
    "!vw -i $PATH_TO_WRITE_DATA/movie_reviews_model2.vw -t -d $PATH_TO_WRITE_DATA/movie_reviews_test.vw \\\n",
    "-p $PATH_TO_WRITE_DATA/movie_test_pred2.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_cell_guid": "527e0327-b208-47a0-9853-2e1bd06beb38",
    "_uuid": "22b7b6feb376fcbd44faf942914afaade9368b30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.888\n",
      "AUC: 0.952\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(PATH_TO_WRITE_DATA, \"movie_test_pred2.txt\")) as pred_file:\n",
    "    test_prediction2 = [float(label) for label in pred_file.readlines()]\n",
    "print(\n",
    "    \"Accuracy: {}\".format(\n",
    "        round(\n",
    "            accuracy_score(\n",
    "                y_test, [int(pred_prob > 0) for pred_prob in test_prediction2]\n",
    "            ),\n",
    "            3,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(y_test, test_prediction2), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a8c85011-e7d2-42c5-8294-34177d6de387",
    "_uuid": "63990db5f343a0e9f44c0069091a66d9f35b954b"
   },
   "source": [
    "Adding bigrams really helped to improve our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "22c8f4bc-07db-44ab-aed5-cab6db73689d",
    "_uuid": "b6c7d300b2f4c9d50358345c5145780f201745ea"
   },
   "source": [
    "### 3.4. Classifying gigabytes of StackOverflow questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f3e9b72a-cc49-49c4-b663-b7df4632cf69",
    "_uuid": "a84523499443d63d08abe83c7a6ebe5bd7c63bf2"
   },
   "source": [
    "This section has been moved to Kaggle, please explore [this Kernel](https://www.kaggle.com/kashnitsky/topic-8-online-learning-and-vowpal-wabbit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "91cbf31e-43a1-482d-af7a-02de3826b00f",
    "_uuid": "bf8903c882ff92061cb8ad971f097734254ed866"
   },
   "source": [
    "## 4. Demo assignment\n",
    "To better understand stochastic learning, you can complete [this assignment](https://www.kaggle.com/kashnitsky/assignment-8-implementing-online-regressor) where you'll be asked to implement a stochastic gradient regressor from scratch. The assignment is just for you to practice, and goes with a [solution](https://www.kaggle.com/kashnitsky/a8-demo-implementing-online-regressor-solution).\n",
    "\n",
    "## 5. Useful resources\n",
    "- The same notebook as am interactive web-based [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-8-online-learning-and-vowpal-wabbit)\n",
    "- [\"Training while reading\"](https://www.kaggle.com/kashnitsky/training-while-reading-vowpal-wabbit-starter) - an example of the Python wrapper usage\n",
    "- Main course [site](https://mlcourse.ai), [course repo](https://github.com/Yorko/mlcourse.ai), and YouTube [channel](https://www.youtube.com/watch?v=QKTuw4PNOsU&list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX)\n",
    "- Course materials as a [Kaggle Dataset](https://www.kaggle.com/kashnitsky/mlcourse)\n",
    "- Official VW [documentation](https://github.com/JohnLangford/vowpal_wabbit/wiki) on Github\n",
    "- [\"Awesome Vowpal Wabbit\"](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Awesome-Vowpal-Wabbit) Wiki\n",
    "- [Don’t be tricked by the Hashing Trick](https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087) - analysis of hash collisions, their dependency on feature space and hashing space dimensions and affecting classification/regression performance\n",
    "- [\"Numeric Computation\" Chapter](http://www.deeplearningbook.org/contents/numerical.html) of the [Deep Learning book](http://www.deeplearningbook.org/)\n",
    "- [\"Convex Optimization\" by Stephen Boyd](https://www.amazon.com/Convex-Optimization-Stephen-Boyd/dp/0521833787)\n",
    "- \"Command-line Tools can be 235x Faster than your Hadoop Cluster\" [post](https://aadrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html)\n",
    "- Benchmarking various ML algorithms on Criteo 1TB dataset on [GitHub](https://github.com/rambler-digital-solutions/criteo-1tb-benchmark)\n",
    "- [VW on FastML.com](http://fastml.com/blog/categories/vw/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
